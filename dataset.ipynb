{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "collapsed": true,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import copy\n",
    "import json\n",
    "import glob\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import nltk as nltk\n",
    "import numpy as np\n",
    "from collections import Counter\n",
    "import math\n",
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "import re\n",
    "from random import shuffle\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "load files, build a graph, count indevidual usages \n",
      "10000 files loaded, for current file: direct_usages = 6 | direct_children = 0 \n",
      "20000 files loaded, for current file: direct_usages = 10 | direct_children = 0 \n",
      "30000 files loaded, for current file: direct_usages = 2 | direct_children = 0 \n",
      "40000 files loaded, for current file: direct_usages = 5 | direct_children = 0 \n",
      "50000 files loaded, for current file: direct_usages = 2 | direct_children = 0 \n",
      "53265 files processed \n"
     ]
    }
   ],
   "source": [
    "root_dir = \"/home/kirill/Documents/1.Projects/\" \\\n",
    "           \"class-ranking/intellij-community/\" \\\n",
    "           \"project-processing-results/processing/\" \\\n",
    "           \"java/classes/processing/0.0.1/\"\n",
    "\n",
    "cnt = 0\n",
    "individualUsages = {}  # {className -> {className -> count}}\n",
    "graph = {}  #{className -> [parentNames]}\n",
    "\n",
    "def good(usage) -> bool:\n",
    "    # {'TYPE', 'THIS_EXPRESSION', 'EXTENDS_LIST', 'IMPLEMENTS_LIST', 'METHOD_REF_EXPRESSION', 'EXPRESSION_LIST', 'NEW_EXPRESSION', 'CONDITIONAL_EXPRESSION', 'FIELD', 'ANNOTATION', 'THROWS_LIST', 'SUPER_EXPRESSION', 'JAVA_CODE_REFERENCE', 'REFERENCE_EXPRESSION', 'DOC_REFERENCE_HOLDER'}\n",
    "    if usage[\"features\"][\"referenceType\"] == \"ANNOTATION\":\n",
    "        return False\n",
    "    if usage[\"features\"][\"referenceType\"] == \"DOC_REFERENCE_HOLDER\":\n",
    "        return False\n",
    "    return True\n",
    "\n",
    "def addToUsages(data, individualUsages):\n",
    "    enclosingName = data[\"keyInfo\"][\"name\"]\n",
    "    c = Counter()\n",
    "    for usage in data['usages']:\n",
    "        if good(usage):\n",
    "            c.update([usage['name']])\n",
    "    individualUsages[enclosingName] = c\n",
    "\n",
    "def addToGraph(data, graph):\n",
    "    enclosingName = data[\"keyInfo\"][\"name\"]\n",
    "    extends = data[\"keyInfo\"][\"additionalInfo\"][\"enclosingClassExtendsList\"]\n",
    "    impls = data[\"keyInfo\"][\"additionalInfo\"][\"enclosingClassImplementsList\"]\n",
    "    if enclosingName not in graph:\n",
    "        graph[enclosingName] = set()\n",
    "    for par in (extends + impls):\n",
    "        if par not in graph:\n",
    "            graph[par] = set()\n",
    "        graph[par].update({enclosingName})\n",
    "\n",
    "\n",
    "print(f'load files, build a graph, count indevidual usages ')\n",
    "for filename in glob.glob(root_dir + '**/*.json', recursive=True):\n",
    "    #print(f'name {filename}')\n",
    "    with open(os.path.join(os.getcwd(), filename), 'r') as f:\n",
    "        data = json.load(f)\n",
    "        addToUsages(data, individualUsages)\n",
    "        addToGraph(data, graph)\n",
    "        cnt += 1\n",
    "        if cnt % 10**4 == 0:\n",
    "            print(f'{cnt} files loaded, for current file: direct_usages = {len(individualUsages[data[\"keyInfo\"][\"name\"]])} | direct_children = {len(graph[data[\"keyInfo\"][\"name\"]])} ')\n",
    "print(f'{cnt} files processed ')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000 vertexes evalueted | in com.intellij.openapi.externalSystem.model.execution.ExternalSystemTaskExecutionSettings used 6 classes, 1 children\n",
      "20000 vertexes evalueted | in com.intellij.codeInspection.SimplifyCollectorInspection used 10 classes, 1 children\n",
      "30000 vertexes evalueted | in com.intellij.refactoring.changeSignature.ChangeSignatureParameterUsageInfo used 2 classes, 1 children\n",
      "40000 vertexes evalueted | in com.intellij.structuralsearch.impl.matcher.MatchResultImpl used 5 classes, 1 children\n",
      "50000 vertexes evalueted | in com.intellij.execution.actions.ChooseDebugConfigurationPopupAction used 2 classes, 1 children\n"
     ]
    }
   ],
   "source": [
    "familyUsages = {} # className -> usages in all children (className -> number)\n",
    "family = {} # className -> self and all children set(className)\n",
    "parent = {} # className -> className\n",
    "def dfs(v):\n",
    "    cur_usages = copy.deepcopy(individualUsages[v])\n",
    "    cur_family_set = {v}\n",
    "    for u in graph[v]:\n",
    "        if u not in family:\n",
    "            parent[u] = v\n",
    "            dfs(u)\n",
    "\n",
    "        u_usages, u_child_set = familyUsages[u], family[u]\n",
    "        cur_usages.update(u_usages)\n",
    "        cur_family_set.update(u_child_set)\n",
    "    familyUsages[v], family[v] = cur_usages, cur_family_set\n",
    "\n",
    "\n",
    "v_count = 0\n",
    "for v in individualUsages:\n",
    "    if v not in familyUsages:\n",
    "        dfs(v)\n",
    "    v_count += 1\n",
    "    if v_count % 10**4 == 0:\n",
    "        print(f'{v_count} vertexes evalueted | in {v} used {len(familyUsages[v])} classes, {len(family[v])} children')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "outputs": [],
   "source": [
    "def listToStr(df, col):\n",
    "    tmp = df[col].isnull(), col\n",
    "    df.loc[tmp] = df.loc[tmp].apply(lambda x: [])\n",
    "    df[col] = df[col].apply(lambda x: \" \".join(x) )"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2810 files loaded \n",
      "test size 79911\n",
      "train size 312111\n"
     ]
    },
    {
     "data": {
      "text/plain": "name                              object\nfeatures.referenceType            object\nfeatures.scopeKind                object\nfeatures.enclosingScopeName       object\nfeatures.enclosingClassName       object\nfeatures.variablesTypesInScope    object\nfeatures.insideStatement_0        object\nfeatures.insideStatement_1        object\nfeatures.insideStatement_2        object\ndtype: object"
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_test_classes = family['com.intellij.openapi.actionSystem.AnAction']\n",
    "train_test_list = list(train_test_classes)\n",
    "shuffle(train_test_list)\n",
    "trainClasses = set(train_test_list[:int(0.8 * len(train_test_list))])\n",
    "testClasses = set(train_test_list[int(0.8 * len(train_test_list)):])\n",
    "\n",
    "cnt = 0\n",
    "list_of_dfs_train = []\n",
    "list_of_dfs_test = []\n",
    "for filename in glob.glob(root_dir + '**/*.json', recursive=True):\n",
    "    with open(os.path.join(os.getcwd(), filename), 'r') as f:\n",
    "        data = json.load(f)\n",
    "        enclosingClassName = data[\"keyInfo\"][\"name\"]\n",
    "        if enclosingClassName not in train_test_classes:\n",
    "            continue\n",
    "        df = pd.json_normalize(data[\"usages\"])\n",
    "        df['features.enclosingClassName'] = enclosingClassName\n",
    "        df = df.drop(columns=['filePath', 'textOffset', 'features.lineInFile'])\n",
    "        if enclosingClassName in trainClasses:\n",
    "            list_of_dfs_train.append(df)\n",
    "        if enclosingClassName in testClasses:\n",
    "            list_of_dfs_test.append(df)\n",
    "        cnt += 1\n",
    "\n",
    "df_train_raw = pd.concat(list_of_dfs_train, axis=0, ignore_index=True)\n",
    "df_test_raw = pd.concat(list_of_dfs_test, axis=0, ignore_index=True)\n",
    "\n",
    "listToStr(df_train_raw, 'features.variablesTypesInScope')\n",
    "listToStr(df_test_raw, 'features.variablesTypesInScope')\n",
    "\n",
    "print(f'{cnt} files loaded ')\n",
    "\n",
    "print(f'test size {df_test_raw.size}')\n",
    "print(f'train size {df_train_raw.size}')\n",
    "df_train_raw.dtypes"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------> :                             name features.referenceType features.scopeKind  \\\n",
      "10  com.intellij.ide.CutProvider                   TYPE             Method   \n",
      "\n",
      "   features.enclosingScopeName         features.enclosingClassName  \\\n",
      "10     getAvailableCutProvider  com.intellij.ide.actions.CutAction   \n",
      "\n",
      "   features.variablesTypesInScope features.insideStatement_0  \\\n",
      "10                                                       NaN   \n",
      "\n",
      "   features.insideStatement_1 features.insideStatement_2  \n",
      "10                        NaN                        NaN  \n"
     ]
    }
   ],
   "source": [
    "print(f'------> : {df_train_raw.loc[[10]]}')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "outputs": [],
   "source": [
    "def splitCamelCase(name: str):\n",
    "    res = []\n",
    "    for rname in name.split(' '):\n",
    "        rname = rname.strip('.')\n",
    "        rname = rname.rpartition('.')[2]\n",
    "        res += re.sub('([A-Z][a-z]+)', r' \\1', re.sub('([A-Z]+)', r' \\1', rname)).split()\n",
    "        #res += [rname]\n",
    "    return res"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "outputs": [],
   "source": [
    "#splitCamelCase('aa.bbKe... ....cc.ddLo')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "outputs": [],
   "source": [
    "#print(df_raw.dtypes)\n",
    "def str_to_OHE_feature(df_train, df_test, col, pref):\n",
    "    vectorizer_train = CountVectorizer(tokenizer=splitCamelCase, lowercase=False, max_features=70)\n",
    "    term_doc_matrix_train = vectorizer_train.fit_transform(df_train[col].values.astype('str'))\n",
    "\n",
    "    #print(f'VOCAB = len=({len(vectorizer_train.vocabulary_)}) {vectorizer_train.vocabulary_}')\n",
    "    vectorizer_test = CountVectorizer(tokenizer=splitCamelCase, lowercase=False, vocabulary=vectorizer_train.vocabulary_)\n",
    "    term_doc_matrix_test = vectorizer_test.fit_transform(df_test[col].values.astype('str'))\n",
    "\n",
    "    df_train_bow = pd.DataFrame(term_doc_matrix_train.toarray(), columns=vectorizer_train.get_feature_names_out())\n",
    "    df_test_bow = pd.DataFrame(term_doc_matrix_test.toarray(), columns=vectorizer_test.get_feature_names_out())\n",
    "    df_train_bow = df_train_bow.add_prefix(pref)\n",
    "    df_test_bow = df_test_bow.add_prefix(pref)\n",
    "\n",
    "    df_train = pd.concat([df_train, df_train_bow], axis=1)\n",
    "    df_test = pd.concat([df_test, df_test_bow], axis=1)\n",
    "\n",
    "    df_train = df_train.drop(columns=[col])\n",
    "    df_test = df_test.drop(columns=[col])\n",
    "\n",
    "    return df_train, df_test\n",
    "\n",
    "# print(vectorizer.get_feature_names())\n",
    "# print(vectorizer.vocabulary_)\n",
    "# print(term_doc_matrix.toarray()[5:10])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train0 ------> :                             name features.referenceType features.scopeKind  \\\n",
      "10  com.intellij.ide.CutProvider                   TYPE             Method   \n",
      "\n",
      "   features.enclosingScopeName         features.enclosingClassName  \\\n",
      "10     getAvailableCutProvider  com.intellij.ide.actions.CutAction   \n",
      "\n",
      "   features.variablesTypesInScope features.insideStatement_0  \\\n",
      "10                                                       NaN   \n",
      "\n",
      "   features.insideStatement_1 features.insideStatement_2  \n",
      "10                        NaN                        NaN  \n",
      "test0 ------> :                               name features.referenceType features.scopeKind  \\\n",
      "10  com.intellij.util.DocumentUtil   REFERENCE_EXPRESSION             Method   \n",
      "\n",
      "   features.enclosingScopeName  features.variablesTypesInScope  \\\n",
      "10           deleteCharAtCaret  FoldRegion int Document Editor   \n",
      "\n",
      "   features.insideStatement_0 features.insideStatement_1  \\\n",
      "10               if_else_body               if_then_body   \n",
      "\n",
      "                         features.enclosingClassName  \\\n",
      "10  com.intellij.openapi.editor.actions.DeleteAction   \n",
      "\n",
      "   features.insideStatement_2  \n",
      "10                        NaN  \n",
      "train1 ------> :    features.referenceType features.scopeKind features.enclosingScopeName  \\\n",
      "10                   TYPE             Method     getAvailableCutProvider   \n",
      "\n",
      "           features.enclosingClassName features.variablesTypesInScope  \\\n",
      "10  com.intellij.ide.actions.CutAction                                  \n",
      "\n",
      "   features.insideStatement_0 features.insideStatement_1  \\\n",
      "10                        NaN                        NaN   \n",
      "\n",
      "   features.insideStatement_2  n_Abstract  n_Action  ...  n_Tool  n_Tree  \\\n",
      "10                        NaN           0         0  ...       0       0   \n",
      "\n",
      "    n_Type  n_UI  n_Util  n_Vcs  n_View  n_Virtual  n_Window  n_X  \n",
      "10       0     0       0      0       0          0         0    0  \n",
      "\n",
      "[1 rows x 78 columns]\n",
      "test1 ------> :    features.referenceType features.scopeKind features.enclosingScopeName  \\\n",
      "10   REFERENCE_EXPRESSION             Method           deleteCharAtCaret   \n",
      "\n",
      "    features.variablesTypesInScope features.insideStatement_0  \\\n",
      "10  FoldRegion int Document Editor               if_else_body   \n",
      "\n",
      "   features.insideStatement_1  \\\n",
      "10               if_then_body   \n",
      "\n",
      "                         features.enclosingClassName  \\\n",
      "10  com.intellij.openapi.editor.actions.DeleteAction   \n",
      "\n",
      "   features.insideStatement_2  n_Abstract  n_Action  ...  n_Tool  n_Tree  \\\n",
      "10                        NaN           0         0  ...       0       0   \n",
      "\n",
      "    n_Type  n_UI  n_Util  n_Vcs  n_View  n_Virtual  n_Window  n_X  \n",
      "10       0     0       1      0       0          0         0    0  \n",
      "\n",
      "[1 rows x 78 columns]\n",
      "train2 ------> :    features.referenceType features.scopeKind features.insideStatement_0  \\\n",
      "10                   TYPE             Method                        NaN   \n",
      "\n",
      "   features.insideStatement_1 features.insideStatement_2  n_Abstract  \\\n",
      "10                        NaN                        NaN           0   \n",
      "\n",
      "    n_Action  n_Actions  n_All  n_An  ...  v.t.s_Tree  v.t.s_Type  \\\n",
      "10         0          0      0     0  ...           0           0   \n",
      "\n",
      "    v.t.s_Usages  v.t.s_Vcs  v.t.s_View  v.t.s_Virtual  v.t.s_Window  v.t.s_X  \\\n",
      "10             0          0           0              0             0        0   \n",
      "\n",
      "    v.t.s_boolean  v.t.s_int  \n",
      "10              0          0  \n",
      "\n",
      "[1 rows x 285 columns]\n",
      "test2 ------> :    features.referenceType features.scopeKind features.insideStatement_0  \\\n",
      "10   REFERENCE_EXPRESSION             Method               if_else_body   \n",
      "\n",
      "   features.insideStatement_1 features.insideStatement_2  n_Abstract  \\\n",
      "10               if_then_body                        NaN           0   \n",
      "\n",
      "    n_Action  n_Actions  n_All  n_An  ...  v.t.s_Tree  v.t.s_Type  \\\n",
      "10         0          0      0     0  ...           0           0   \n",
      "\n",
      "    v.t.s_Usages  v.t.s_Vcs  v.t.s_View  v.t.s_Virtual  v.t.s_Window  v.t.s_X  \\\n",
      "10             0          0           0              0             0        0   \n",
      "\n",
      "    v.t.s_boolean  v.t.s_int  \n",
      "10              0          1  \n",
      "\n",
      "[1 rows x 285 columns]\n"
     ]
    }
   ],
   "source": [
    "df_train, df_test = df_train_raw, df_test_raw\n",
    "print(f'train0 ------> : {df_train.loc[[10]]}')\n",
    "print(f'test0 ------> : {df_test.loc[[10]]}')\n",
    "df_train, df_test = str_to_OHE_feature(df_train, df_test, 'name', pref='n_')\n",
    "print(f'train1 ------> : {df_train.loc[[10]]}')\n",
    "print(f'test1 ------> : {df_test.loc[[10]]}')\n",
    "df_train, df_test = str_to_OHE_feature(df_train, df_test, 'features.enclosingScopeName', pref='e.s.n_')\n",
    "df_train, df_test = str_to_OHE_feature(df_train, df_test, 'features.enclosingClassName', pref='e.c.n_')\n",
    "df_train, df_test = str_to_OHE_feature(df_train, df_test, 'features.variablesTypesInScope', pref='v.t.s_')\n",
    "print(f'train2 ------> : {df_train.loc[[10]]}')\n",
    "print(f'test2 ------> : {df_test.loc[[10]]}')\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}