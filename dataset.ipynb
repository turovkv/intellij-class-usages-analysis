{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import copy\n",
    "import json\n",
    "import glob\n",
    "import os\n",
    "import random\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import nltk as nltk\n",
    "import numpy as np\n",
    "from collections import Counter\n",
    "import math\n",
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "import re\n",
    "from random import shuffle\n",
    "import random\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "load files, build a graph, count indevidual usages \n",
      "10000 files loaded, for current file: direct_usages = 6 | direct_children = 0 \n",
      "20000 files loaded, for current file: direct_usages = 10 | direct_children = 0 \n",
      "30000 files loaded, for current file: direct_usages = 2 | direct_children = 0 \n",
      "40000 files loaded, for current file: direct_usages = 5 | direct_children = 0 \n",
      "50000 files loaded, for current file: direct_usages = 2 | direct_children = 0 \n",
      "53265 files processed \n"
     ]
    }
   ],
   "source": [
    "root_dir = \"/home/kirill/Documents/1.Projects/\" \\\n",
    "           \"class-ranking/intellij-community/\" \\\n",
    "           \"project-processing-results/processing/\" \\\n",
    "           \"java/classes/processing/0.0.1/\"\n",
    "\n",
    "cnt = 0\n",
    "individualUsages = {}  # {className -> {className -> count}}\n",
    "graph = {}  #{className -> [parentNames]}\n",
    "\n",
    "def good(usage) -> bool:\n",
    "    # {'TYPE', 'THIS_EXPRESSION', 'EXTENDS_LIST', 'IMPLEMENTS_LIST', 'METHOD_REF_EXPRESSION', 'EXPRESSION_LIST', 'NEW_EXPRESSION', 'CONDITIONAL_EXPRESSION', 'FIELD', 'ANNOTATION', 'THROWS_LIST', 'SUPER_EXPRESSION', 'JAVA_CODE_REFERENCE', 'REFERENCE_EXPRESSION', 'DOC_REFERENCE_HOLDER'}\n",
    "    if usage[\"features\"][\"referenceType\"] == \"ANNOTATION\":\n",
    "        return False\n",
    "    if usage[\"features\"][\"referenceType\"] == \"DOC_REFERENCE_HOLDER\":\n",
    "        return False\n",
    "    return True\n",
    "\n",
    "def addToUsages(data, individualUsages):\n",
    "    enclosingName = data[\"keyInfo\"][\"name\"]\n",
    "    c = Counter()\n",
    "    for usage in data['usages']:\n",
    "        if good(usage):\n",
    "            c.update([usage['name']])\n",
    "    individualUsages[enclosingName] = c\n",
    "\n",
    "def addToGraph(data, graph):\n",
    "    enclosingName = data[\"keyInfo\"][\"name\"]\n",
    "    extends = data[\"keyInfo\"][\"additionalInfo\"][\"enclosingClassExtendsList\"]\n",
    "    impls = data[\"keyInfo\"][\"additionalInfo\"][\"enclosingClassImplementsList\"]\n",
    "    if enclosingName not in graph:\n",
    "        graph[enclosingName] = set()\n",
    "    for par in (extends + impls):\n",
    "        if par not in graph:\n",
    "            graph[par] = set()\n",
    "        graph[par].update({enclosingName})\n",
    "\n",
    "\n",
    "print(f'load files, build a graph, count indevidual usages ')\n",
    "for filename in glob.glob(root_dir + '**/*.json', recursive=True):\n",
    "    #print(f'name {filename}')\n",
    "    with open(os.path.join(os.getcwd(), filename), 'r') as f:\n",
    "        data = json.load(f)\n",
    "        addToUsages(data, individualUsages)\n",
    "        addToGraph(data, graph)\n",
    "        cnt += 1\n",
    "        if cnt % 10**4 == 0:\n",
    "            print(f'{cnt} files loaded, for current file: direct_usages = {len(individualUsages[data[\"keyInfo\"][\"name\"]])} | direct_children = {len(graph[data[\"keyInfo\"][\"name\"]])} ')\n",
    "print(f'{cnt} files processed ')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000 vertexes evalueted | in com.intellij.openapi.externalSystem.model.execution.ExternalSystemTaskExecutionSettings used 6 classes, 1 children\n",
      "20000 vertexes evalueted | in com.intellij.codeInspection.SimplifyCollectorInspection used 10 classes, 1 children\n",
      "30000 vertexes evalueted | in com.intellij.refactoring.changeSignature.ChangeSignatureParameterUsageInfo used 2 classes, 1 children\n",
      "40000 vertexes evalueted | in com.intellij.structuralsearch.impl.matcher.MatchResultImpl used 5 classes, 1 children\n",
      "50000 vertexes evalueted | in com.intellij.execution.actions.ChooseDebugConfigurationPopupAction used 2 classes, 1 children\n"
     ]
    }
   ],
   "source": [
    "familyUsages = {} # className -> usages in all children (className -> number)\n",
    "family = {} # className -> self and all children set(className)\n",
    "parent = {} # className -> className\n",
    "def dfs(v):\n",
    "    cur_usages = copy.deepcopy(individualUsages[v])\n",
    "    cur_family_set = {v}\n",
    "    for u in graph[v]:\n",
    "        if u not in family:\n",
    "            parent[u] = v\n",
    "            dfs(u)\n",
    "\n",
    "        u_usages, u_child_set = familyUsages[u], family[u]\n",
    "        cur_usages.update(u_usages)\n",
    "        cur_family_set.update(u_child_set)\n",
    "    familyUsages[v], family[v] = cur_usages, cur_family_set\n",
    "\n",
    "\n",
    "v_count = 0\n",
    "for v in individualUsages:\n",
    "    if v not in familyUsages:\n",
    "        dfs(v)\n",
    "    v_count += 1\n",
    "    if v_count % 10**4 == 0:\n",
    "        print(f'{v_count} vertexes evalueted | in {v} used {len(familyUsages[v])} classes, {len(family[v])} children')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [],
   "source": [
    "ROOT_CLASS = \"com.intellij.openapi.actionSystem.AnAction\"\n",
    "#print(familyUsages[ROOT_CLASS].most_common())"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [],
   "source": [
    "firstCharToNameList = {}\n",
    "for k, v in familyUsages[ROOT_CLASS].most_common():\n",
    "    first_char = k.rpartition('.')[2][0]\n",
    "    if first_char not in firstCharToNameList:\n",
    "        firstCharToNameList[first_char] = []\n",
    "    firstCharToNameList[first_char].append(k)\n",
    "\n",
    "with open('FirstCharToNameList.txt', 'w') as convert_file:\n",
    "     convert_file.write(json.dumps(firstCharToNameList))\n",
    "\n",
    "# for k in firstCharToNameList:\n",
    "#     print(f'{k} {len(firstCharToNameList[k])}')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [],
   "source": [
    "firstCharToNameListSampling = {}\n",
    "for k, v in familyUsages[ROOT_CLASS].most_common():\n",
    "    first_char = k.rpartition('.')[2][0]\n",
    "    if first_char not in firstCharToNameListSampling:\n",
    "        firstCharToNameListSampling[first_char] = []\n",
    "    firstCharToNameListSampling[first_char] += [k] * v\n",
    "\n",
    "for k in firstCharToNameListSampling:\n",
    "    shuffle(firstCharToNameListSampling[k])\n",
    "\n",
    "with open('FirstCharToNameListSampling.txt', 'w') as convert_file:\n",
    "     convert_file.write(json.dumps(firstCharToNameList))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [],
   "source": [
    "def listToStr(df, col):\n",
    "    tmp = df[col].isnull(), col\n",
    "    df.loc[tmp] = df.loc[tmp].apply(lambda x: [])\n",
    "    df[col] = df[col].apply(lambda x: \" \".join(x) )"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2810 files loaded, 343728 usages\n",
      "test shape (72792, 12)\n",
      "train shape (270936, 12)\n"
     ]
    },
    {
     "data": {
      "text/plain": "name                              object\ncorrect                            int64\nfirstChar                         object\ngroup                              int64\nfeatures.referenceType            object\nfeatures.scopeKind                object\nfeatures.enclosingScopeName       object\nfeatures.enclosingClassName       object\nfeatures.variablesTypesInScope    object\nfeatures.insideStatement_0        object\nfeatures.insideStatement_1        object\nfeatures.insideStatement_2        object\ndtype: object"
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_test_classes = family[ROOT_CLASS]\n",
    "train_test_list = list(train_test_classes)\n",
    "shuffle(train_test_list)\n",
    "trainClasses = set(train_test_list[:int(0.8 * len(train_test_list))])\n",
    "testClasses = set(train_test_list[int(0.8 * len(train_test_list)):])\n",
    "\n",
    "cnt = 0\n",
    "cntu = 0\n",
    "list_of_dfs_train = []\n",
    "list_of_dfs_test = []\n",
    "group_id = 0\n",
    "for filename in glob.glob(root_dir + '**/*.json', recursive=True):\n",
    "    with open(os.path.join(os.getcwd(), filename), 'r') as f:\n",
    "        data = json.load(f)\n",
    "        enclosingClassName = data[\"keyInfo\"][\"name\"]\n",
    "        if enclosingClassName not in train_test_classes:\n",
    "            continue\n",
    "\n",
    "        data_usages = []\n",
    "        for usage in data[\"usages\"]:\n",
    "            if not good(usage):\n",
    "                continue\n",
    "            usage['correct'] = 1\n",
    "            usage['firstChar'] = usage['name'].rpartition('.')[2][0]\n",
    "            usage['group'] = group_id\n",
    "            group_id += 1\n",
    "            data_usages.append(usage)\n",
    "\n",
    "            for i in range(7):\n",
    "                usage_negative = copy.deepcopy(usage)\n",
    "                while True:\n",
    "                    new_name = random.choice(firstCharToNameListSampling[usage['firstChar']]) #?\n",
    "                    if usage['name'] != new_name:\n",
    "                        usage_negative['name'] = new_name\n",
    "                        usage_negative['correct'] = 0\n",
    "                        break\n",
    "                data_usages.append(usage_negative)\n",
    "\n",
    "        df = pd.json_normalize(data_usages)\n",
    "        df['features.enclosingClassName'] = enclosingClassName\n",
    "\n",
    "        df = df.drop(columns=['filePath', 'textOffset', 'features.lineInFile'])\n",
    "        if enclosingClassName in trainClasses:\n",
    "            list_of_dfs_train.append(df)\n",
    "        if enclosingClassName in testClasses:\n",
    "            list_of_dfs_test.append(df)\n",
    "        cntu += len(data_usages)\n",
    "        cnt += 1\n",
    "\n",
    "df_train_raw = pd.concat(list_of_dfs_train, axis=0, ignore_index=True)\n",
    "df_test_raw = pd.concat(list_of_dfs_test, axis=0, ignore_index=True)\n",
    "\n",
    "listToStr(df_train_raw, 'features.variablesTypesInScope')\n",
    "listToStr(df_test_raw, 'features.variablesTypesInScope')\n",
    "df_train_raw.fillna('', inplace=True)\n",
    "df_test_raw.fillna('', inplace=True)\n",
    "\n",
    "print(f'{cnt} files loaded, {cntu} usages')\n",
    "\n",
    "print(f'test shape {df_test_raw.shape}')\n",
    "print(f'train shape {df_train_raw.shape}')\n",
    "df_train_raw.dtypes\n",
    "\n",
    "# will we know referenceType irl ?"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "outputs": [],
   "source": [
    "def splitCamelCase(name: str):\n",
    "    res = []\n",
    "    for rname in name.split(' '):\n",
    "        rname = rname.strip('.')\n",
    "        if '.' in rname:\n",
    "            rname = rname.rpartition('.')[2]\n",
    "        res += re.sub('([A-Z][a-z]+)', r' \\1', re.sub('([A-Z]+)', r' \\1', rname)).split()\n",
    "        #res += [rname]\n",
    "    return res"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "outputs": [],
   "source": [
    "def str_to_OHE_feature(df_train, df_test, col, pref, max_features=80, replace_columns=True):\n",
    "    vectorizer_train = CountVectorizer(tokenizer=splitCamelCase, lowercase=False, max_features=max_features)\n",
    "    term_doc_matrix_train = vectorizer_train.fit_transform(df_train[col].values.astype('str'))\n",
    "\n",
    "    vectorizer_test = CountVectorizer(tokenizer=splitCamelCase, lowercase=False, vocabulary=vectorizer_train.vocabulary_)\n",
    "    term_doc_matrix_test = vectorizer_test.fit_transform(df_test[col].values.astype('str'))\n",
    "\n",
    "    df_train_bow = pd.DataFrame(term_doc_matrix_train.toarray(), columns=vectorizer_train.get_feature_names_out())\n",
    "    df_test_bow = pd.DataFrame(term_doc_matrix_test.toarray(), columns=vectorizer_test.get_feature_names_out())\n",
    "    df_train_bow = df_train_bow.add_prefix(pref)\n",
    "    df_test_bow = df_test_bow.add_prefix(pref)\n",
    "\n",
    "    df_train = pd.concat([df_train, df_train_bow], axis=1)\n",
    "    df_test = pd.concat([df_test, df_test_bow], axis=1)\n",
    "\n",
    "    if replace_columns:\n",
    "        df_train = df_train.drop(columns=[col])\n",
    "        df_test = df_test.drop(columns=[col])\n",
    "\n",
    "    return df_train, df_test"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train0 ########## ------> :\n",
      "                                       name  correct firstChar  group  \\\n",
      "10  com.intellij.psi.xml.XmlAttributeValue        0         X      1   \n",
      "\n",
      "   features.referenceType features.scopeKind   features.enclosingScopeName  \\\n",
      "10                   TYPE             Method  startComputingSourcePosition   \n",
      "\n",
      "                          features.enclosingClassName  \\\n",
      "10  com.intellij.xdebugger.impl.ui.tree.actions.XJ...   \n",
      "\n",
      "   features.variablesTypesInScope features.insideStatement_0  \\\n",
      "10                                                             \n",
      "\n",
      "   features.insideStatement_1 features.insideStatement_2  \n",
      "10                                                        \n",
      "test0  ########## ------> :\n",
      "                                                name  correct firstChar  group  \\\n",
      "10  com.intellij.openapi.actionSystem.ex.ActionUtil        0         A     25   \n",
      "\n",
      "   features.referenceType features.scopeKind features.enclosingScopeName  \\\n",
      "10                   TYPE             Method             actionPerformed   \n",
      "\n",
      "                          features.enclosingClassName  \\\n",
      "10  com.intellij.ide.palette.impl.PaletteWindow.Cl...   \n",
      "\n",
      "   features.variablesTypesInScope features.insideStatement_0  \\\n",
      "10                                                             \n",
      "\n",
      "   features.insideStatement_1 features.insideStatement_2  \n",
      "10                                                        \n",
      "train1 ########## ------> :\n",
      "                                       name  correct firstChar  group  \\\n",
      "10  com.intellij.psi.xml.XmlAttributeValue        0         X      1   \n",
      "\n",
      "    name_Abstract  name_Action  name_Actions  name_All  name_An  \\\n",
      "10              0            0             0         0        0   \n",
      "\n",
      "    name_Application  ...  insideStatement1_while_body  \\\n",
      "10                 0  ...                            0   \n",
      "\n",
      "    insideStatement2_finally  insideStatement2_for_body  \\\n",
      "10                         0                          0   \n",
      "\n",
      "    insideStatement2_foreach_body  insideStatement2_if_condition  \\\n",
      "10                              0                              0   \n",
      "\n",
      "    insideStatement2_if_else_body  insideStatement2_if_then_body  \\\n",
      "10                              0                              0   \n",
      "\n",
      "    insideStatement2_return  insideStatement2_try  insideStatement2_while_body  \n",
      "10                        0                     0                            0  \n",
      "\n",
      "[1 rows x 402 columns]\n",
      "test1  ########## ------> :\n",
      "                                                name  correct firstChar  group  \\\n",
      "10  com.intellij.openapi.actionSystem.ex.ActionUtil        0         A     25   \n",
      "\n",
      "    name_Abstract  name_Action  name_Actions  name_All  name_An  \\\n",
      "10              0            1             0         0        0   \n",
      "\n",
      "    name_Application  ...  insideStatement1_while_body  \\\n",
      "10                 0  ...                            0   \n",
      "\n",
      "    insideStatement2_finally  insideStatement2_for_body  \\\n",
      "10                         0                          0   \n",
      "\n",
      "    insideStatement2_foreach_body  insideStatement2_if_condition  \\\n",
      "10                              0                              0   \n",
      "\n",
      "    insideStatement2_if_else_body  insideStatement2_if_then_body  \\\n",
      "10                              0                              0   \n",
      "\n",
      "    insideStatement2_return  insideStatement2_try  insideStatement2_while_body  \n",
      "10                        0                     0                            0  \n",
      "\n",
      "[1 rows x 402 columns]\n"
     ]
    }
   ],
   "source": [
    "df_train, df_test = df_train_raw, df_test_raw\n",
    "print(f'train0 ########## ------> :\\n {df_train.loc[[10]]}')\n",
    "print(f'test0  ########## ------> :\\n {df_test.loc[[10]]}')\n",
    "df_train, df_test = str_to_OHE_feature(df_train, df_test, 'name', pref='name_', max_features=100, replace_columns=False)\n",
    "df_train, df_test = str_to_OHE_feature(df_train, df_test, 'features.enclosingScopeName', pref='enclosingScopeName_')\n",
    "df_train, df_test = str_to_OHE_feature(df_train, df_test, 'features.enclosingClassName', pref='enclosingClassName_')\n",
    "df_train, df_test = str_to_OHE_feature(df_train, df_test, 'features.variablesTypesInScope', pref='variablesTypesInScope_')\n",
    "df_train, df_test = str_to_OHE_feature(df_train, df_test, 'features.referenceType', pref='referenceType_')\n",
    "df_train, df_test = str_to_OHE_feature(df_train, df_test, 'features.scopeKind', pref='scopeKind_')\n",
    "df_train, df_test = str_to_OHE_feature(df_train, df_test, 'features.insideStatement_0', pref='insideStatement0_')\n",
    "df_train, df_test = str_to_OHE_feature(df_train, df_test, 'features.insideStatement_1', pref='insideStatement1_')\n",
    "df_train, df_test = str_to_OHE_feature(df_train, df_test, 'features.insideStatement_2', pref='insideStatement2_')\n",
    "\n",
    "\n",
    "#firstChar,features.referenceType,features.scopeKind,features.insideStatement_0,features.insideStatement_1,features.insideStatement_2\n",
    "\n",
    "print(f'train1 ########## ------> :\\n {df_train.loc[[10]]}')\n",
    "print(f'test1  ########## ------> :\\n {df_test.loc[[10]]}')\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "outputs": [],
   "source": [
    "df_train.to_csv('train.csv')\n",
    "df_train_raw.to_csv('train_raw.csv')\n",
    "\n",
    "df_test.to_csv('test.csv')\n",
    "df_test_raw.to_csv('test_raw.csv')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train ########## ------> : (270936, 402)\n",
      "test ########## ------> : (72792, 402)\n"
     ]
    }
   ],
   "source": [
    "print(f'train ########## ------> : {df_train.shape}')\n",
    "print(f'test ########## ------> : {df_test.shape}')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}