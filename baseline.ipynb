{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 29,
   "outputs": [],
   "source": [
    "import copy\n",
    "import json\n",
    "import glob\n",
    "import os\n",
    "import random\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import nltk as nltk\n",
    "import numpy as np\n",
    "from collections import Counter\n",
    "import math\n",
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "import re\n",
    "from random import shuffle\n",
    "import random\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn.metrics import median_absolute_error\n",
    "from sklearn import svm\n",
    "\n",
    "from catboost import CatBoostRegressor, Pool\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_61431/1479892705.py:1: DtypeWarning: Columns (7) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  train = pd.read_csv('train.csv', index_col=0).sample(frac=1)\n",
      "/tmp/ipykernel_61431/1479892705.py:5: DtypeWarning: Columns (7) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  test = pd.read_csv('test.csv', index_col=0).sample(frac=1)\n"
     ]
    },
    {
     "data": {
      "text/plain": "25"
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train = pd.read_csv('train.csv', index_col=0).sample(frac=1)\n",
    "y_train = train['correct']\n",
    "X_train = train.drop(columns=['correct'])\n",
    "\n",
    "test = pd.read_csv('test.csv', index_col=0).sample(frac=1)\n",
    "y_test = test['correct']\n",
    "X_test = test.drop(columns=['correct'])\n",
    "\n",
    "test_r = pd.read_csv('test_raw.csv', index_col=0).sample(frac=1)\n",
    "y_test_r = test_r['correct']\n",
    "X_test_r = test_r.drop(columns=['correct'])\n",
    "\n",
    "\n",
    "with open(os.path.join(os.getcwd(), 'randomNames.txt'), 'r') as f:\n",
    "        randomNames = json.load(f)\n",
    "\n",
    "len(randomNames)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "outputs": [],
   "source": [
    "y_test_pred = []\n",
    "for ind in X_test_r.index:\n",
    "        name = str(X_test_r['name'][ind])\n",
    "        first = name.rpartition('.')[2][0]\n",
    "        val = 0\n",
    "        for i, v in enumerate(randomNames[first]):\n",
    "               if v == name:\n",
    "                       val = i\n",
    "        val = 1 - val / len(randomNames[first])\n",
    "        y_test_pred.append(val)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "outputs": [
    {
     "data": {
      "text/plain": "[0.16825095057034223,\n 0.623006833712984,\n 0.12274881516587677,\n 0.5370729343348679,\n 0.33220256845165985,\n 0.4486692015209125,\n 0.16185503685503688,\n 0.5551839464882944,\n 0.45512449334105387,\n 0.3085308056872038,\n 0.3424447174447175,\n 0.623006833712984,\n 0.30060422960725075,\n 0.8459964932787843,\n 0.489406779661017,\n 0.23237218318391084,\n 0.25658965180605275,\n 0.8723404255319149,\n 0.5969889982628835,\n 0.4237160120845922,\n 0.06687276277253495,\n 0.1583054626532887,\n 0.046971569839307836,\n 0.7273413897280967,\n 0.5370729343348679,\n 0.39173405211141055,\n 0.7085106382978723,\n 0.3237872589129164,\n 0.09692270414344561,\n 0.8580645161290322,\n 0.06409013811485342,\n 0.051903677188415265,\n 0.5370729343348679,\n 0.7026055705300989,\n 0.5370729343348679,\n 0.6625592417061612,\n 0.7121705174096974,\n 0.16961473225102985,\n 0.7121705174096974,\n 0.17804154302670627,\n 0.02779386218876667,\n 0.2611454604620892,\n 0.36733556298773695,\n 0.5007552870090635,\n 0.2779258541313303,\n 0.39146919431279625,\n 0.2511848341232228,\n 0.6541935483870968,\n 0.4774985388661601,\n 0.09674447174447176,\n 0.41246290801186947,\n 0.6800847457627119,\n 0.6907248157248157,\n 0.3853889023503756,\n 0.5891566265060241,\n 0.135372600065083,\n 0.7903614457831325,\n 0.0906103286384976,\n 0.0455873758036236,\n 0.655893536121673,\n 0.24647887323943662,\n 0.6405367231638418,\n 0.5530120481927712,\n 0.3853889023503756,\n 0.17035470224536287,\n 0.33121468926553677,\n 0.7163781624500666,\n 0.30284301606922126,\n 0.23237218318391084,\n 0.623006833712984,\n 0.1800947867298578,\n 0.5370729343348679,\n 0.8967468175388967,\n 0.27615429573348915,\n 0.5102459016393442,\n 0.4171819069313375,\n 0.23906844106463876,\n 0.41262419637638803,\n 0.3625806451612903,\n 0.7121705174096974,\n 0.5390497884803124,\n 0.882943143812709,\n 0.7163781624500666,\n 0.5370729343348679,\n 0.5370729343348679,\n 0.5370729343348679,\n 0.3853889023503756,\n 0.414004914004914,\n 0.5244131455399061,\n 0.4932614555256065,\n 0.5370729343348679,\n 0.690793283149971,\n 0.18760856977417484,\n 0.36826867400115804,\n 0.5729857819905213,\n 0.7227722772277227,\n 0.32345013477088946,\n 0.4753554502369668,\n 0.18572813181487768,\n 0.6016949152542372,\n 0.690793283149971,\n 0.665983606557377,\n 0.5242628992628993,\n 0.8580645161290322,\n 0.7137440758293838,\n 0.04115479115479115,\n 0.690793283149971,\n 0.5693916349809887,\n 0.34675141242937857,\n 0.6984219754529515,\n 0.3034398034398035,\n 0.2744807121661721,\n 0.623006833712984,\n 0.09029807130333134,\n 0.1911928651059086,\n 0.2154838709677419,\n 0.8373764600179694,\n 0.22242108688577933,\n 0.21142433234421365,\n 0.13049267643142481,\n 0.9182389937106918,\n 0.6984219754529515,\n 0.24647887323943662,\n 0.33804809052333806,\n 0.7641277641277642,\n 0.5423728813559322,\n 0.18393536121673004,\n 0.220034742327736,\n 0.7121705174096974,\n 0.3739017246989912,\n 0.9182389937106918,\n 0.6636977886977886,\n 0.04712866488975043,\n 0.22909209241783268,\n 0.6170616113744076,\n 0.5042372881355932,\n 0.5370729343348679,\n 0.6984219754529515,\n 0.2040059347181009,\n 0.4582309582309583,\n 0.15179760319573898,\n 0.8459964932787843,\n 0.7984790874524714,\n 0.2123818754543252,\n 0.6984219754529515,\n 0.015023019142234029,\n 0.8668032786885246,\n 0.8723404255319149,\n 0.023917995444191376,\n 0.3445280833815866,\n 0.623006833712984,\n 0.882943143812709,\n 0.03726000650829808,\n 0.7121705174096974,\n 0.6761290322580645,\n 0.1005573055488248,\n 0.12127453355948636,\n 0.11339956384783134,\n 0.5370729343348679,\n 0.5370729343348679,\n 0.5370729343348679,\n 0.3739017246989912,\n 0.7163781624500666,\n 0.040327293980128576,\n 0.32085909534656687,\n 0.8187608569774175,\n 0.1297552701720378,\n 0.29238529124633905,\n 0.648036253776435,\n 0.6625592417061612,\n 0.5370729343348679,\n 0.7121705174096974,\n 0.7690925426774483,\n 0.5620393120393121,\n 0.4178403755868545,\n 0.05915492957746482,\n 0.6567834681042228,\n 0.33220256845165985,\n 0.04372623574144485,\n 0.5244131455399061,\n 0.4879518072289156,\n 0.07640949554896137,\n 0.3135245901639344,\n 0.12391430225825129,\n 0.09759036144578315,\n 0.34132086499123315,\n 0.617014742014742,\n 0.1546033584250145,\n 0.5898791540785498,\n 0.13460140537921006,\n 0.3739017246989912,\n 0.27518427518427513,\n 0.19590501574993946,\n 0.5390497884803124,\n 0.7273413897280967,\n 0.5370729343348679,\n 0.5484790874524714,\n 0.371007371007371,\n 0.0556379821958457,\n 0.33220256845165985,\n 0.12127453355948636,\n 0.5370729343348679,\n 0.03586140053307485,\n 0.39147412951513183,\n 0.3387592137592138,\n 0.4514742014742015,\n 0.8459964932787843,\n 0.7137440758293838,\n 0.23338048090523333,\n 0.08388814913448739,\n 0.0494471744471745,\n 0.33333333333333337,\n 0.6984219754529515,\n 0.5370729343348679,\n 0.17076167076167081,\n 0.21077012159814712,\n 0.5274881516587677,\n 0.7641277641277642,\n 0.6984219754529515,\n 0.34337349397590367,\n 0.37592137592137587,\n 0.5774804905239688,\n 0.41825095057034223,\n 0.6405367231638418,\n 0.6203208556149733,\n 0.5099809885931559,\n 0.30445844439059855,\n 0.18375499334221035,\n 0.211864406779661,\n 0.5370729343348679,\n 0.2123818754543252,\n 0.14580645161290318,\n 0.32531824611032534,\n 0.21125975473801561,\n 0.6636977886977886,\n 0.7163781624500666,\n 0.3525821596244132,\n 0.5489614243323442,\n 0.4437032216075496,\n 0.7121705174096974,\n 0.8057909604519774,\n 0.40264127764127766,\n 0.882943143812709,\n 0.09125475285171103,\n 0.12010520163646987,\n 0.046697038724373585,\n 0.25357402471528956,\n 0.5555230859146698,\n 0.2783924503742271,\n 0.8459964932787843,\n 0.5244131455399061,\n 0.6721311475409837,\n 0.5370729343348679,\n 0.11601402688486262,\n 0.5244131455399061,\n 0.4437032216075496,\n 0.5370729343348679,\n 0.3146919431279621,\n 0.3853889023503756,\n 0.7121705174096974,\n 0.1493920092646207,\n 0.6016949152542372,\n 0.11596958174904948,\n 0.38636363636363635,\n 0.5390497884803124,\n 0.7121705174096974,\n 0.419431279620853,\n 0.3208530805687204,\n 0.10093896713615025,\n 0.6984219754529515,\n 0.8459964932787843,\n 0.7121705174096974,\n 0.24170761670761676,\n 0.4171819069313375,\n 0.5244131455399061,\n 0.3853889023503756,\n 0.882943143812709,\n 0.5244131455399061,\n 0.33127317676143386,\n 0.5086551264980026,\n 0.3109677419354838,\n 0.3853889023503756,\n 0.5304154302670623,\n 0.6625592417061612,\n 0.17203791469194318,\n 0.11117544875506657,\n 0.2053191489361702,\n 0.5244131455399061,\n 0.6761290322580645,\n 0.37762669962917184,\n 0.1906103286384977,\n 0.4516587677725118,\n 0.4919653893695921,\n 0.4521276595744681,\n 0.29431438127090304,\n 0.2668402212821347,\n 0.04637592137592139,\n 0.42048517520215634,\n 0.8459964932787843,\n 0.8987642585551331,\n 0.43032329988851725,\n 0.623006833712984,\n 0.4334600760456274,\n 0.5042372881355932,\n 0.7893617021276595,\n 0.3029661016949152,\n 0.5729857819905213,\n 0.5244131455399061,\n 0.882943143812709,\n 0.3099576960624797,\n 0.4486692015209125,\n 0.1574468085106383,\n 0.6361702127659574,\n 0.15883208141507144,\n 0.1714501510574018,\n 0.3387592137592138,\n 0.46144578313253015,\n 0.13423364790107384,\n 0.14296098861158224,\n 0.6716833890746934,\n 0.5370729343348679,\n 0.5370729343348679,\n 0.25357402471528956,\n 0.23157248157248156,\n 0.021040327293980088,\n 0.4703872437357631,\n 0.5555230859146698,\n 0.751425855513308,\n 0.22580645161290325,\n 0.4171819069313375,\n 0.2123818754543252,\n 0.04054054054054057,\n 0.882943143812709,\n 0.0662650602409639,\n 0.08192090395480223,\n 0.33220256845165985,\n 0.3830985915492958,\n 0.7121705174096974,\n 0.013935340022296572,\n 0.10559713634884482,\n 0.7893617021276595,\n 0.30211817168338906,\n 0.6203208556149733,\n 0.1467621217051741,\n 0.5118694362017804,\n 0.4774985388661601,\n 0.3739017246989912,\n 0.23237218318391084,\n 0.7163781624500666,\n 0.7137440758293838,\n 0.7961290322580645,\n 0.33220256845165985,\n 0.06101529450048815,\n 0.4437032216075496,\n 0.12333414102253448,\n 0.7137440758293838,\n 0.3853889023503756,\n 0.3208530805687204,\n 0.30211817168338906,\n 0.06451612903225812,\n 0.014457831325301207,\n 0.5242395437262357,\n 0.9182389937106918,\n 0.43620178041543023,\n 0.36265060240963853,\n 0.7121705174096974,\n 0.5242395437262357,\n 0.009859154929577452,\n 0.18572813181487768,\n 0.42008196721311475,\n 0.3438008460787504,\n 0.06253618992472498,\n 0.5952088452088452,\n 0.042282529682578174,\n 0.29041248606465997,\n 0.9406528189910979,\n 0.42622950819672134,\n 0.13855421686746983,\n 0.26906779661016944,\n 0.5370729343348679,\n 0.9264524103831892,\n 0.690793283149971,\n 0.9264524103831892,\n 0.2779258541313303,\n 0.048218673218673236,\n 0.3853889023503756,\n 0.5555230859146698,\n 0.25357402471528956,\n 0.23968042609853524,\n 0.5370729343348679,\n 0.3957636566332219,\n 0.002457002457002422,\n 0.6984219754529515,\n 0.2637832699619772,\n 0.8199554069119286,\n 0.7121705174096974,\n 0.3525821596244132,\n 0.3830985915492958,\n 0.4610266159695817,\n 0.22867737948084055,\n 0.5242395437262357,\n 0.5244131455399061,\n 0.03389830508474578,\n 0.4171819069313375,\n 0.1977886977886978,\n 0.3655589123867069,\n 0.2779258541313303,\n 0.7121705174096974,\n 0.6170616113744076,\n 0.23348918760958504,\n 0.47745901639344257,\n 0.053672316384180796,\n 0.511977886977887,\n 0.882943143812709,\n 0.08196721311475408,\n 0.27034559643255296,\n 0.15079852579852582,\n 0.7394067796610169,\n 0.4486404833836858,\n 0.6223479490806223,\n 0.15969581749049433,\n 0.4371742906774754,\n 0.4399717514124294,\n 0.3144654088050315,\n 0.41223733003708285,\n 0.3853889023503756,\n 0.9241803278688525,\n 0.20094786729857816,\n 0.3853889023503756,\n 0.09934577174703174,\n 0.882943143812709,\n 0.4108433734939759,\n 0.7137440758293838,\n 0.6625592417061612,\n 0.7893617021276595,\n 0.5555230859146698,\n 0.8459964932787843,\n 0.7121705174096974,\n 0.23237218318391084,\n 0.69106463878327,\n 0.4703872437357631,\n 0.8967468175388967,\n 0.15171990171990168,\n 0.7121705174096974,\n 0.19590501574993946,\n 0.4437032216075496,\n 0.5007552870090635,\n 0.6625592417061612,\n 0.7903614457831325,\n 0.7121705174096974,\n 0.5729857819905213,\n 0.8459964932787843,\n 0.5370729343348679,\n 0.3525821596244132,\n 0.35674470457079155,\n 0.3146919431279621,\n 0.3853889023503756,\n 0.5086551264980026,\n 0.25357402471528956,\n 0.7227722772277227,\n 0.11830985915492953,\n 0.19754529514903563,\n 0.6907248157248157,\n 0.9241803278688525,\n 0.5370729343348679,\n 0.882943143812709,\n 0.14803625377643503,\n 0.14117647058823535,\n 0.7121705174096974,\n 0.3829383886255924,\n 0.7394067796610169,\n 0.7272727272727273,\n 0.6854140914709518,\n 0.40264127764127766,\n 0.8879518072289156,\n 0.1320208453966416,\n 0.8459964932787843,\n 0.520392749244713,\n 0.40648523451071217,\n 0.4171819069313375,\n 0.5370729343348679,\n 0.636144578313253,\n 0.44106463878326996,\n 0.3892460549386324,\n 0.7641277641277642,\n 0.623006833712984,\n 0.3445280833815866,\n 0.5244131455399061,\n 0.6907248157248157,\n 0.46439169139465875,\n 0.5370729343348679,\n 0.06296778392450375,\n 0.20761670761670759,\n 0.12127453355948636,\n 0.5244131455399061,\n 0.5370729343348679,\n 0.7137440758293838,\n 0.7273413897280967,\n 0.524526198439242,\n 0.6625592417061612,\n 0.26335311572700293,\n 0.4453734671125975,\n 0.882943143812709,\n 0.7641277641277642,\n 0.2123818754543252,\n 0.05211141060197666,\n 0.14582115721800115,\n 0.03529411764705881,\n 0.22369668246445495,\n 0.4610266159695817,\n 0.7903614457831325,\n 0.21244886031560495,\n 0.623006833712984,\n 0.33208590953465666,\n 0.38963210702341133,\n 0.7641277641277642,\n 0.042282529682578174,\n 0.7121705174096974,\n 0.7251950947603121,\n 0.025531914893617058,\n 0.617014742014742,\n 0.18572813181487768,\n 0.7273413897280967,\n 0.10964373464373467,\n 0.19590501574993946,\n 0.37848383500557414,\n 0.47235872235872234,\n 0.4358006042296072,\n 0.024243410348193994,\n 0.07947661739762535,\n 0.1800445930880713,\n 0.28037904124860646,\n 0.4774985388661601,\n 0.02544220983765444,\n 0.29953051643192485,\n 0.636144578313253,\n 0.7121705174096974,\n 0.44106463878326996,\n 0.08795180722891571,\n 0.7227722772277227,\n 0.35012285012285016,\n 0.1311475409836066,\n 0.32385661310259584,\n 0.7641277641277642,\n 0.6993548387096774,\n 0.8580645161290322,\n 0.7961290322580645,\n 0.5150501672240803,\n 0.3635014836795252,\n 0.5390497884803124,\n 0.055851708262660504,\n 0.24749163879598657,\n 0.17951807228915662,\n 0.18572813181487768,\n 0.882943143812709,\n 0.21513353115727007,\n 0.46350710900473935,\n 0.5242395437262357,\n 0.15531863338987162,\n 0.15945611866501852,\n 0.2668402212821347,\n 0.06551297898640296,\n 0.3853889023503756,\n 0.7961290322580645,\n 0.6984219754529515,\n 0.5370729343348679,\n 0.1443488943488943,\n 0.5370729343348679,\n 0.5464454976303317,\n 0.5555230859146698,\n 0.5274881516587677,\n 0.7121705174096974,\n 0.4171819069313375,\n 0.2779258541313303,\n 0.2650602409638554,\n 0.5031847133757962,\n 0.1823529411764706,\n 0.623006833712984,\n 0.7121705174096974,\n 0.10322267991276957,\n 0.5952088452088452,\n 0.8182941903584673,\n 0.623006833712984,\n 0.08281829419035847,\n 0.8373764600179694,\n 0.049429657794676785,\n 0.7641277641277642,\n 0.14296098861158224,\n 0.5390497884803124,\n 0.3853889023503756,\n 0.1610169491525424,\n 0.06101529450048815,\n 0.2699530516431925,\n 0.3389830508474576,\n 0.7026055705300989,\n 0.1758293838862559,\n 0.7641277641277642,\n 0.18572813181487768,\n 0.33220256845165985,\n 0.5370729343348679,\n 0.3853889023503756,\n 0.3853889023503756,\n 0.882943143812709,\n 0.8199554069119286,\n 0.3278688524590164,\n 0.18572813181487768,\n 0.5370729343348679,\n 0.7121705174096974,\n 0.4178403755868545,\n 0.18811881188118806,\n 0.5361702127659574,\n 0.5390497884803124,\n 0.3853889023503756,\n 0.6106304079110012,\n 0.69106463878327,\n 0.7137440758293838,\n 0.07856191744340879,\n 0.09735872235872234,\n 0.8702101359703338,\n 0.7714604236343366,\n 0.4759887005649718,\n 0.6967670011148273,\n 0.8987642585551331,\n 0.5367689635205559,\n 0.1962441314553991,\n 0.5244131455399061,\n 0.6276477146042363,\n 0.020491803278688492,\n 0.7641277641277642,\n 0.24697885196374625,\n 0.46350710900473935,\n 0.3853889023503756,\n 0.42906774753908516,\n 0.5390497884803124,\n 0.8987642585551331,\n 0.157802454704851,\n 0.00694846554719164,\n 0.43981042654028435,\n 0.7108433734939759,\n 0.882943143812709,\n 0.03889023503755751,\n 0.06118245699055003,\n 0.2002457002457002,\n 0.08141507148049432,\n 0.29954441913439633,\n 0.055851708262660504,\n 0.4787234042553191,\n 0.7641277641277642,\n 0.32085909534656687,\n 0.5370729343348679,\n 0.04675628287551137,\n 0.2971311475409836,\n 0.2256752359258054,\n 0.7251950947603121,\n 0.7273413897280967,\n 0.7714604236343366,\n 0.11533801793070031,\n 0.4629107981220657,\n 0.17076167076167081,\n 0.22496909765142148,\n 0.8359264497878359,\n 0.33220256845165985,\n 0.22242108688577933,\n 0.40648523451071217,\n 0.7273413897280967,\n 0.27349397590361446,\n 0.3830985915492958,\n 0.4811178247734139,\n 0.23237218318391084,\n 0.41544607190412786,\n 0.10322267991276957,\n 0.04637592137592139,\n 0.2339316734221193,\n 0.4876777251184834,\n 0.7121705174096974,\n 0.3586072242108689,\n 0.751425855513308,\n 0.5891566265060241,\n 0.23904149620105197,\n 0.10588805427671433,\n 0.5367689635205559,\n 0.7121705174096974,\n 0.3853889023503756,\n 0.8887240356083086,\n 0.23906844106463876,\n 0.6588380716934488,\n 0.623006833712984,\n 0.9406528189910979,\n 0.07856191744340879,\n 0.8373764600179694,\n 0.31083650190114065,\n 0.8199554069119286,\n 0.39147412951513183,\n 0.05725699067909451,\n 0.32085909534656687,\n 0.0691031941031941,\n 0.17781493868450393,\n 0.08674582020838384,\n 0.3294314381270903,\n 0.39830508474576276,\n 0.8987642585551331,\n 0.40264127764127766,\n 0.6644486692015209,\n 0.4171819069313375,\n 0.25357402471528956,\n 0.6854140914709518,\n 0.062146892655367214,\n 0.3503798947983635,\n 0.22580645161290325,\n 0.49665551839464883,\n 0.5370729343348679,\n 0.8459964932787843,\n 0.8459964932787843,\n 0.5530120481927712,\n 0.0537697253068381,\n 0.16666666666666663,\n 0.3853889023503756,\n 0.7641277641277642,\n 0.05915492957746482,\n 0.07787391841779978,\n 0.21621621621621623,\n 0.5555230859146698,\n 0.3853889023503756,\n 0.031499878846619866,\n 0.8373764600179694,\n 0.28192771084337354,\n 0.33178922987840187,\n 0.7641277641277642,\n 0.23529411764705888,\n 0.038573933372296865,\n 0.5244131455399061,\n 0.8359264497878359,\n 0.8459964932787843,\n 0.5244131455399061,\n 0.18572813181487768,\n 0.33220256845165985,\n 0.5244131455399061,\n 0.5491400491400491,\n 0.5370729343348679,\n 0.13117870722433456,\n 0.5370729343348679,\n 0.036619718309859106,\n 0.019286966686148488,\n 0.6854140914709518,\n 0.7641277641277642,\n 0.8182941903584673,\n 0.06364922206506363,\n 0.5345596432552955,\n 0.4753554502369668,\n 0.5370729343348679,\n 0.02619843924191745,\n 0.7273413897280967,\n 0.20748100526008184,\n 0.11455399061032867,\n 0.5370729343348679,\n 0.04667609618104662,\n 0.5361702127659574,\n 0.7121705174096974,\n 0.4777503090234858,\n 0.5390497884803124,\n 0.6716833890746934,\n 0.7137440758293838,\n 0.48241444866920147,\n 0.8057909604519774,\n 0.5370729343348679,\n 0.5370729343348679,\n 0.022501461133839884,\n 0.6967670011148273,\n 0.7029467680608366,\n 0.4703872437357631,\n 0.6907248157248157,\n 0.6397420147420148,\n 0.4774985388661601,\n 0.4171819069313375,\n 0.32085909534656687,\n 0.21160933660933656,\n 0.5304154302670623,\n 0.8609625668449198,\n 0.8723404255319149,\n 0.05564594858444516,\n 0.7121705174096974,\n 0.33208590953465666,\n 0.20748100526008184,\n 0.5555230859146698,\n 0.6984219754529515,\n 0.7641277641277642,\n 0.6761290322580645,\n 0.6170616113744076,\n 0.520392749244713,\n 0.2779258541313303,\n 0.33220256845165985,\n 0.30167921250723795,\n 0.7137440758293838,\n 0.5675074183976261,\n 0.4927620150550087,\n 0.6541935483870968,\n 0.22235872235872234,\n 0.690793283149971,\n 0.24777448071216612,\n 0.5370729343348679,\n 0.623006833712984,\n 0.7218100890207715,\n 0.5370729343348679,\n 0.26335311572700293,\n 0.5390497884803124,\n 0.10588805427671433,\n 0.3853889023503756,\n 0.7447466007416563,\n 0.3853889023503756,\n 0.30445844439059855,\n 0.5370729343348679,\n 0.08192090395480223,\n 0.5491400491400491,\n 0.13493975903614452,\n 0.4703872437357631,\n 0.5365479115479115,\n 0.194672131147541,\n 0.5370729343348679,\n 0.8459964932787843,\n 0.4013353115727003,\n 0.9241803278688525,\n 0.4582309582309583,\n 0.07481005260081819,\n 0.14296098861158224,\n 0.7587096774193548,\n 0.4541203974284045,\n 0.623006833712984,\n 0.06161137440758291,\n 0.639344262295082,\n 0.4927620150550087,\n 0.33534743202416917,\n 0.5693916349809887,\n 0.7108433734939759,\n 0.18874064432150994,\n 0.6397420147420148,\n 0.6170616113744076,\n 0.6127049180327868,\n 0.22822910578609001,\n 0.21404682274247488,\n 0.7137440758293838,\n 0.5370729343348679,\n 0.17813267813267808,\n 0.29894798363530095,\n 0.2779258541313303,\n 0.13651155222909206,\n 0.3867469879518072,\n 0.29161290322580646,\n 0.6045272969374168,\n 0.4687083888149135,\n 0.5370729343348679,\n 0.4140127388535032,\n 0.8459964932787843,\n 0.2277227722772277,\n 0.2123818754543252,\n 0.5244131455399061,\n 0.5370729343348679,\n 0.0029222676797194813,\n 0.02515723270440251,\n 0.33220256845165985,\n 0.5808510638297872,\n 0.11830985915492953,\n 0.4108433734939759,\n 0.26919431279620853,\n 0.5244131455399061,\n 0.0957345971563981,\n 0.8987642585551331,\n 0.3319148936170213,\n 0.10588805427671433,\n 0.40264127764127766,\n 0.23237218318391084,\n 0.690793283149971,\n 0.2860451650260567,\n 0.12127453355948636,\n 0.22629107981220653,\n 0.028228737581778574,\n 0.7121705174096974,\n 0.7121705174096974,\n 0.8987642585551331,\n 0.4516587677725118,\n 0.5370729343348679,\n 0.3099576960624797,\n 0.8057909604519774,\n 0.06674907292954269,\n 0.18450390189520627,\n 0.09571117034165255,\n 0.34132086499123315,\n 0.41262419637638803,\n 0.11339956384783134,\n 0.15179760319573898,\n 0.1297552701720378,\n 0.4774985388661601,\n 0.05352112676056342,\n 0.8187608569774175,\n 0.5555230859146698,\n 0.16423144360023378,\n 0.8459964932787843,\n 0.31531268264172996,\n 0.5803231939163498,\n 0.5370729343348679,\n 0.6223479490806223,\n 0.9264524103831892,\n 0.46350710900473935,\n 0.7714604236343366,\n 0.623006833712984,\n 0.16961473225102985,\n 0.39199395770392753,\n 0.6644486692015209,\n 0.5370729343348679,\n 0.30713033313851545,\n 0.3283169533169533,\n 0.2779258541313303,\n 0.22243346007604559,\n 0.14418066010422703,\n 0.35419440745672437,\n 0.23237218318391084,\n 0.12653419053185266,\n 0.1492395437262357,\n 0.8199554069119286,\n 0.05660377358490565,\n 0.28314997104806017,\n 0.8987642585551331,\n 0.14936544093719495,\n 0.022296544035674493,\n 0.8459964932787843,\n 0.7137440758293838,\n 0.4158305462653289,\n 0.43620178041543023,\n 0.6116920152091254,\n 0.13493975903614452,\n 0.4629107981220657,\n 0.30445844439059855,\n 0.6800847457627119,\n 0.5370729343348679,\n 0.25357402471528956,\n 0.12170517409697368,\n 0.7264516129032258,\n 0.021080688151199456,\n 0.623006833712984,\n 0.3739017246989912,\n 0.40638297872340423,\n 0.17377155873739014,\n 0.4687083888149135,\n 0.648036253776435,\n 0.4178403755868545,\n 0.8879518072289156,\n 0.2800982800982801,\n 0.07947661739762535,\n 0.1488975042403683,\n 0.04734073641145531,\n 0.18572813181487768,\n 0.7121705174096974,\n 0.3099576960624797,\n 0.4108433734939759,\n 0.17688393506178823,\n 0.5774804905239688,\n 0.5361702127659574,\n 0.8459964932787843,\n 0.36265060240963853,\n 0.8359264497878359,\n 0.2834599649327878,\n 0.13154960981047936,\n 0.7273413897280967,\n 0.11170341652532101,\n 0.8879518072289156,\n 0.5370729343348679,\n 0.2611454604620892,\n 0.3853889023503756,\n 0.31084337349397595,\n 0.11389521640091116,\n 0.22629107981220653,\n 0.882943143812709,\n 0.2779258541313303,\n 0.6045272969374168,\n 0.5192771084337349,\n 0.5390497884803124,\n 0.7137440758293838,\n 0.9264524103831892,\n 0.0014836795252225476,\n 0.2274011299435028,\n 0.8879518072289156,\n 0.8199554069119286,\n 0.31084337349397595,\n 0.08565543978677004,\n 0.8616920152091254,\n 0.6907248157248157,\n 0.08044584443905989,\n 0.17680608365019013,\n 0.5489614243323442,\n 0.7121705174096974,\n 0.04519774011299438,\n 0.2361502347417841,\n 0.8260456273764258,\n 0.06385542168674696,\n 0.19901719901719905,\n 0.020826553856166607,\n 0.0066710055320533534,\n 0.33427230046948353,\n 0.3967213114754098,\n 0.7121705174096974,\n 0.4035846724351051,\n ...]"
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test_pred"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "outputs": [
    {
     "data": {
      "text/plain": "0.2638804279567999"
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean_squared_error(y_test_r.tolist(), y_test_pred)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "outputs": [
    {
     "data": {
      "text/plain": "-0.6492526747299987"
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r2_score(y_test_r.tolist(), y_test_pred)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "outputs": [
    {
     "data": {
      "text/plain": "0.4541203974284045"
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "median_absolute_error(y_test_r.tolist(), y_test_pred)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "could not convert string to float: 'A'",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mValueError\u001B[0m                                Traceback (most recent call last)",
      "Input \u001B[0;32mIn [23]\u001B[0m, in \u001B[0;36m<cell line: 2>\u001B[0;34m()\u001B[0m\n\u001B[1;32m      1\u001B[0m regr \u001B[38;5;241m=\u001B[39m svm\u001B[38;5;241m.\u001B[39mSVR()\n\u001B[0;32m----> 2\u001B[0m \u001B[43mregr\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mfit\u001B[49m\u001B[43m(\u001B[49m\u001B[43mX_train\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43my_train\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m      3\u001B[0m y_pred \u001B[38;5;241m=\u001B[39m regr\u001B[38;5;241m.\u001B[39mpredict(X_test)\n",
      "File \u001B[0;32m~/Documents/1.Projects/class-ranking/intellij-class-usages-analysis/venv/lib/python3.8/site-packages/sklearn/svm/_base.py:190\u001B[0m, in \u001B[0;36mBaseLibSVM.fit\u001B[0;34m(self, X, y, sample_weight)\u001B[0m\n\u001B[1;32m    188\u001B[0m     check_consistent_length(X, y)\n\u001B[1;32m    189\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m--> 190\u001B[0m     X, y \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_validate_data\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m    191\u001B[0m \u001B[43m        \u001B[49m\u001B[43mX\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    192\u001B[0m \u001B[43m        \u001B[49m\u001B[43my\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    193\u001B[0m \u001B[43m        \u001B[49m\u001B[43mdtype\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mnp\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mfloat64\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    194\u001B[0m \u001B[43m        \u001B[49m\u001B[43morder\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mC\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m,\u001B[49m\n\u001B[1;32m    195\u001B[0m \u001B[43m        \u001B[49m\u001B[43maccept_sparse\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mcsr\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m,\u001B[49m\n\u001B[1;32m    196\u001B[0m \u001B[43m        \u001B[49m\u001B[43maccept_large_sparse\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43;01mFalse\u001B[39;49;00m\u001B[43m,\u001B[49m\n\u001B[1;32m    197\u001B[0m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    199\u001B[0m y \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_validate_targets(y)\n\u001B[1;32m    201\u001B[0m sample_weight \u001B[38;5;241m=\u001B[39m np\u001B[38;5;241m.\u001B[39masarray(\n\u001B[1;32m    202\u001B[0m     [] \u001B[38;5;28;01mif\u001B[39;00m sample_weight \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m \u001B[38;5;28;01melse\u001B[39;00m sample_weight, dtype\u001B[38;5;241m=\u001B[39mnp\u001B[38;5;241m.\u001B[39mfloat64\n\u001B[1;32m    203\u001B[0m )\n",
      "File \u001B[0;32m~/Documents/1.Projects/class-ranking/intellij-class-usages-analysis/venv/lib/python3.8/site-packages/sklearn/base.py:581\u001B[0m, in \u001B[0;36mBaseEstimator._validate_data\u001B[0;34m(self, X, y, reset, validate_separately, **check_params)\u001B[0m\n\u001B[1;32m    579\u001B[0m         y \u001B[38;5;241m=\u001B[39m check_array(y, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mcheck_y_params)\n\u001B[1;32m    580\u001B[0m     \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m--> 581\u001B[0m         X, y \u001B[38;5;241m=\u001B[39m \u001B[43mcheck_X_y\u001B[49m\u001B[43m(\u001B[49m\u001B[43mX\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43my\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mcheck_params\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    582\u001B[0m     out \u001B[38;5;241m=\u001B[39m X, y\n\u001B[1;32m    584\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m no_val_X \u001B[38;5;129;01mand\u001B[39;00m check_params\u001B[38;5;241m.\u001B[39mget(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mensure_2d\u001B[39m\u001B[38;5;124m\"\u001B[39m, \u001B[38;5;28;01mTrue\u001B[39;00m):\n",
      "File \u001B[0;32m~/Documents/1.Projects/class-ranking/intellij-class-usages-analysis/venv/lib/python3.8/site-packages/sklearn/utils/validation.py:964\u001B[0m, in \u001B[0;36mcheck_X_y\u001B[0;34m(X, y, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, multi_output, ensure_min_samples, ensure_min_features, y_numeric, estimator)\u001B[0m\n\u001B[1;32m    961\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m y \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[1;32m    962\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mValueError\u001B[39;00m(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124my cannot be None\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n\u001B[0;32m--> 964\u001B[0m X \u001B[38;5;241m=\u001B[39m \u001B[43mcheck_array\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m    965\u001B[0m \u001B[43m    \u001B[49m\u001B[43mX\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    966\u001B[0m \u001B[43m    \u001B[49m\u001B[43maccept_sparse\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43maccept_sparse\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    967\u001B[0m \u001B[43m    \u001B[49m\u001B[43maccept_large_sparse\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43maccept_large_sparse\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    968\u001B[0m \u001B[43m    \u001B[49m\u001B[43mdtype\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mdtype\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    969\u001B[0m \u001B[43m    \u001B[49m\u001B[43morder\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43morder\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    970\u001B[0m \u001B[43m    \u001B[49m\u001B[43mcopy\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mcopy\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    971\u001B[0m \u001B[43m    \u001B[49m\u001B[43mforce_all_finite\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mforce_all_finite\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    972\u001B[0m \u001B[43m    \u001B[49m\u001B[43mensure_2d\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mensure_2d\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    973\u001B[0m \u001B[43m    \u001B[49m\u001B[43mallow_nd\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mallow_nd\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    974\u001B[0m \u001B[43m    \u001B[49m\u001B[43mensure_min_samples\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mensure_min_samples\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    975\u001B[0m \u001B[43m    \u001B[49m\u001B[43mensure_min_features\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mensure_min_features\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    976\u001B[0m \u001B[43m    \u001B[49m\u001B[43mestimator\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mestimator\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    977\u001B[0m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    979\u001B[0m y \u001B[38;5;241m=\u001B[39m _check_y(y, multi_output\u001B[38;5;241m=\u001B[39mmulti_output, y_numeric\u001B[38;5;241m=\u001B[39my_numeric)\n\u001B[1;32m    981\u001B[0m check_consistent_length(X, y)\n",
      "File \u001B[0;32m~/Documents/1.Projects/class-ranking/intellij-class-usages-analysis/venv/lib/python3.8/site-packages/sklearn/utils/validation.py:746\u001B[0m, in \u001B[0;36mcheck_array\u001B[0;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, estimator)\u001B[0m\n\u001B[1;32m    744\u001B[0m         array \u001B[38;5;241m=\u001B[39m array\u001B[38;5;241m.\u001B[39mastype(dtype, casting\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124munsafe\u001B[39m\u001B[38;5;124m\"\u001B[39m, copy\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mFalse\u001B[39;00m)\n\u001B[1;32m    745\u001B[0m     \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m--> 746\u001B[0m         array \u001B[38;5;241m=\u001B[39m \u001B[43mnp\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43masarray\u001B[49m\u001B[43m(\u001B[49m\u001B[43marray\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43morder\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43morder\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mdtype\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mdtype\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    747\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m ComplexWarning \u001B[38;5;28;01mas\u001B[39;00m complex_warning:\n\u001B[1;32m    748\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mValueError\u001B[39;00m(\n\u001B[1;32m    749\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mComplex data not supported\u001B[39m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[38;5;132;01m{}\u001B[39;00m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;241m.\u001B[39mformat(array)\n\u001B[1;32m    750\u001B[0m     ) \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mcomplex_warning\u001B[39;00m\n",
      "File \u001B[0;32m~/Documents/1.Projects/class-ranking/intellij-class-usages-analysis/venv/lib/python3.8/site-packages/pandas/core/generic.py:2064\u001B[0m, in \u001B[0;36mNDFrame.__array__\u001B[0;34m(self, dtype)\u001B[0m\n\u001B[1;32m   2063\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21m__array__\u001B[39m(\u001B[38;5;28mself\u001B[39m, dtype: npt\u001B[38;5;241m.\u001B[39mDTypeLike \u001B[38;5;241m|\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m) \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m>\u001B[39m np\u001B[38;5;241m.\u001B[39mndarray:\n\u001B[0;32m-> 2064\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mnp\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43masarray\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_values\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mdtype\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mdtype\u001B[49m\u001B[43m)\u001B[49m\n",
      "\u001B[0;31mValueError\u001B[0m: could not convert string to float: 'A'"
     ]
    }
   ],
   "source": [
    "regr = svm.SVR()\n",
    "regr.fit(X_train, y_train)\n",
    "y_pred = regr.predict(X_test)\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "median_absolute_error(y_test.tolist(), y_pred)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "outputs": [
    {
     "ename": "CatBoostError",
     "evalue": "Invalid type for cat_feature[non-default value idx=24,feature_idx=2]=nan : cat_features must be integer or string, real number values and NaN values should be converted to string.",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mCatBoostError\u001B[0m                             Traceback (most recent call last)",
      "File \u001B[0;32m_catboost.pyx:2244\u001B[0m, in \u001B[0;36m_catboost.get_cat_factor_bytes_representation\u001B[0;34m()\u001B[0m\n",
      "File \u001B[0;32m_catboost.pyx:1856\u001B[0m, in \u001B[0;36m_catboost.get_id_object_bytes_string_representation\u001B[0;34m()\u001B[0m\n",
      "\u001B[0;31mCatBoostError\u001B[0m: bad object for id: nan",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001B[0;31mCatBoostError\u001B[0m                             Traceback (most recent call last)",
      "Input \u001B[0;32mIn [31]\u001B[0m, in \u001B[0;36m<cell line: 6>\u001B[0;34m()\u001B[0m\n\u001B[1;32m      2\u001B[0m model \u001B[38;5;241m=\u001B[39m CatBoostRegressor(iterations\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m2\u001B[39m,\n\u001B[1;32m      3\u001B[0m                           learning_rate\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m1\u001B[39m,\n\u001B[1;32m      4\u001B[0m                           depth\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m2\u001B[39m)\n\u001B[1;32m      5\u001B[0m \u001B[38;5;66;03m# Fit model\u001B[39;00m\n\u001B[0;32m----> 6\u001B[0m \u001B[43mmodel\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mfit\u001B[49m\u001B[43m(\u001B[49m\u001B[43mX_train\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43my_train\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mcat_features\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43m[\u001B[49m\u001B[38;5;241;43m0\u001B[39;49m\u001B[43m,\u001B[49m\u001B[38;5;241;43m1\u001B[39;49m\u001B[43m,\u001B[49m\u001B[38;5;241;43m2\u001B[39;49m\u001B[43m,\u001B[49m\u001B[38;5;241;43m3\u001B[39;49m\u001B[43m,\u001B[49m\u001B[38;5;241;43m4\u001B[39;49m\u001B[43m,\u001B[49m\u001B[38;5;241;43m5\u001B[39;49m\u001B[43m]\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m      7\u001B[0m \u001B[38;5;66;03m# Get predictions\u001B[39;00m\n\u001B[1;32m      8\u001B[0m preds \u001B[38;5;241m=\u001B[39m model\u001B[38;5;241m.\u001B[39mpredict(X_test)\n",
      "File \u001B[0;32m~/Documents/1.Projects/class-ranking/intellij-class-usages-analysis/venv/lib/python3.8/site-packages/catboost/core.py:5504\u001B[0m, in \u001B[0;36mCatBoostRegressor.fit\u001B[0;34m(self, X, y, cat_features, sample_weight, baseline, use_best_model, eval_set, verbose, logging_level, plot, column_description, verbose_eval, metric_period, silent, early_stopping_rounds, save_snapshot, snapshot_file, snapshot_interval, init_model, callbacks, log_cout, log_cerr)\u001B[0m\n\u001B[1;32m   5501\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mloss_function\u001B[39m\u001B[38;5;124m'\u001B[39m \u001B[38;5;129;01min\u001B[39;00m params:\n\u001B[1;32m   5502\u001B[0m     CatBoostRegressor\u001B[38;5;241m.\u001B[39m_check_is_compatible_loss(params[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mloss_function\u001B[39m\u001B[38;5;124m'\u001B[39m])\n\u001B[0;32m-> 5504\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_fit\u001B[49m\u001B[43m(\u001B[49m\u001B[43mX\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43my\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mcat_features\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43;01mNone\u001B[39;49;00m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43;01mNone\u001B[39;49;00m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43;01mNone\u001B[39;49;00m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43msample_weight\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43;01mNone\u001B[39;49;00m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43;01mNone\u001B[39;49;00m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43;01mNone\u001B[39;49;00m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43;01mNone\u001B[39;49;00m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mbaseline\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   5505\u001B[0m \u001B[43m                 \u001B[49m\u001B[43muse_best_model\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43meval_set\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mverbose\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mlogging_level\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mplot\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mcolumn_description\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   5506\u001B[0m \u001B[43m                 \u001B[49m\u001B[43mverbose_eval\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mmetric_period\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43msilent\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mearly_stopping_rounds\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   5507\u001B[0m \u001B[43m                 \u001B[49m\u001B[43msave_snapshot\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43msnapshot_file\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43msnapshot_interval\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43minit_model\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mcallbacks\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mlog_cout\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mlog_cerr\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/Documents/1.Projects/class-ranking/intellij-class-usages-analysis/venv/lib/python3.8/site-packages/catboost/core.py:2176\u001B[0m, in \u001B[0;36mCatBoost._fit\u001B[0;34m(self, X, y, cat_features, text_features, embedding_features, pairs, sample_weight, group_id, group_weight, subgroup_id, pairs_weight, baseline, use_best_model, eval_set, verbose, logging_level, plot, column_description, verbose_eval, metric_period, silent, early_stopping_rounds, save_snapshot, snapshot_file, snapshot_interval, init_model, callbacks, log_cout, log_cerr)\u001B[0m\n\u001B[1;32m   2173\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m y \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m \u001B[38;5;129;01mand\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(X, PATH_TYPES \u001B[38;5;241m+\u001B[39m (Pool,)):\n\u001B[1;32m   2174\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m CatBoostError(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124my may be None only when X is an instance of catboost.Pool or string\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n\u001B[0;32m-> 2176\u001B[0m train_params \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_prepare_train_params\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m   2177\u001B[0m \u001B[43m    \u001B[49m\u001B[43mX\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mX\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43my\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43my\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mcat_features\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mcat_features\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mtext_features\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mtext_features\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43membedding_features\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43membedding_features\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   2178\u001B[0m \u001B[43m    \u001B[49m\u001B[43mpairs\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mpairs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43msample_weight\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43msample_weight\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mgroup_id\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mgroup_id\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mgroup_weight\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mgroup_weight\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   2179\u001B[0m \u001B[43m    \u001B[49m\u001B[43msubgroup_id\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43msubgroup_id\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mpairs_weight\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mpairs_weight\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mbaseline\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mbaseline\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43muse_best_model\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43muse_best_model\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   2180\u001B[0m \u001B[43m    \u001B[49m\u001B[43meval_set\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43meval_set\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mverbose\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mverbose\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mlogging_level\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mlogging_level\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mplot\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mplot\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   2181\u001B[0m \u001B[43m    \u001B[49m\u001B[43mcolumn_description\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mcolumn_description\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mverbose_eval\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mverbose_eval\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mmetric_period\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mmetric_period\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   2182\u001B[0m \u001B[43m    \u001B[49m\u001B[43msilent\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43msilent\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mearly_stopping_rounds\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mearly_stopping_rounds\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43msave_snapshot\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43msave_snapshot\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   2183\u001B[0m \u001B[43m    \u001B[49m\u001B[43msnapshot_file\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43msnapshot_file\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43msnapshot_interval\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43msnapshot_interval\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43minit_model\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43minit_model\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   2184\u001B[0m \u001B[43m    \u001B[49m\u001B[43mcallbacks\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mcallbacks\u001B[49m\n\u001B[1;32m   2185\u001B[0m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   2186\u001B[0m params \u001B[38;5;241m=\u001B[39m train_params[\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mparams\u001B[39m\u001B[38;5;124m\"\u001B[39m]\n\u001B[1;32m   2187\u001B[0m train_pool \u001B[38;5;241m=\u001B[39m train_params[\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mtrain_pool\u001B[39m\u001B[38;5;124m\"\u001B[39m]\n",
      "File \u001B[0;32m~/Documents/1.Projects/class-ranking/intellij-class-usages-analysis/venv/lib/python3.8/site-packages/catboost/core.py:2062\u001B[0m, in \u001B[0;36mCatBoost._prepare_train_params\u001B[0;34m(self, X, y, cat_features, text_features, embedding_features, pairs, sample_weight, group_id, group_weight, subgroup_id, pairs_weight, baseline, use_best_model, eval_set, verbose, logging_level, plot, column_description, verbose_eval, metric_period, silent, early_stopping_rounds, save_snapshot, snapshot_file, snapshot_interval, init_model, callbacks)\u001B[0m\n\u001B[1;32m   2059\u001B[0m text_features \u001B[38;5;241m=\u001B[39m _process_feature_indices(text_features, X, params, \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mtext_features\u001B[39m\u001B[38;5;124m'\u001B[39m)\n\u001B[1;32m   2060\u001B[0m embedding_features \u001B[38;5;241m=\u001B[39m _process_feature_indices(embedding_features, X, params, \u001B[38;5;124m'\u001B[39m\u001B[38;5;124membedding_features\u001B[39m\u001B[38;5;124m'\u001B[39m)\n\u001B[0;32m-> 2062\u001B[0m train_pool \u001B[38;5;241m=\u001B[39m \u001B[43m_build_train_pool\u001B[49m\u001B[43m(\u001B[49m\u001B[43mX\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43my\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mcat_features\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mtext_features\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43membedding_features\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mpairs\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   2063\u001B[0m \u001B[43m                               \u001B[49m\u001B[43msample_weight\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mgroup_id\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mgroup_weight\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43msubgroup_id\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mpairs_weight\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   2064\u001B[0m \u001B[43m                               \u001B[49m\u001B[43mbaseline\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mcolumn_description\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   2065\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m train_pool\u001B[38;5;241m.\u001B[39mis_empty_:\n\u001B[1;32m   2066\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m CatBoostError(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mX is empty.\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n",
      "File \u001B[0;32m~/Documents/1.Projects/class-ranking/intellij-class-usages-analysis/venv/lib/python3.8/site-packages/catboost/core.py:1344\u001B[0m, in \u001B[0;36m_build_train_pool\u001B[0;34m(X, y, cat_features, text_features, embedding_features, pairs, sample_weight, group_id, group_weight, subgroup_id, pairs_weight, baseline, column_description)\u001B[0m\n\u001B[1;32m   1342\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m y \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[1;32m   1343\u001B[0m         \u001B[38;5;28;01mraise\u001B[39;00m CatBoostError(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124my has not initialized in fit(): X is not catboost.Pool object, y must be not None in fit().\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n\u001B[0;32m-> 1344\u001B[0m     train_pool \u001B[38;5;241m=\u001B[39m \u001B[43mPool\u001B[49m\u001B[43m(\u001B[49m\u001B[43mX\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43my\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mcat_features\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mcat_features\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mtext_features\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mtext_features\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43membedding_features\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43membedding_features\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mpairs\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mpairs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mweight\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43msample_weight\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mgroup_id\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mgroup_id\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1345\u001B[0m \u001B[43m                      \u001B[49m\u001B[43mgroup_weight\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mgroup_weight\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43msubgroup_id\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43msubgroup_id\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mpairs_weight\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mpairs_weight\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mbaseline\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mbaseline\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   1346\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m train_pool\n",
      "File \u001B[0;32m~/Documents/1.Projects/class-ranking/intellij-class-usages-analysis/venv/lib/python3.8/site-packages/catboost/core.py:748\u001B[0m, in \u001B[0;36mPool.__init__\u001B[0;34m(self, data, label, cat_features, text_features, embedding_features, column_description, pairs, delimiter, has_header, ignore_csv_quoting, weight, group_id, group_weight, subgroup_id, pairs_weight, baseline, timestamp, feature_names, feature_tags, thread_count, log_cout, log_cerr)\u001B[0m\n\u001B[1;32m    742\u001B[0m         \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(feature_names, PATH_TYPES):\n\u001B[1;32m    743\u001B[0m             \u001B[38;5;28;01mraise\u001B[39;00m CatBoostError(\n\u001B[1;32m    744\u001B[0m                 \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mfeature_names must be None or have non-string type when the pool is created from \u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m    745\u001B[0m                 \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mpython objects.\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m    746\u001B[0m             )\n\u001B[0;32m--> 748\u001B[0m         \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_init\u001B[49m\u001B[43m(\u001B[49m\u001B[43mdata\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mlabel\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mcat_features\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mtext_features\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43membedding_features\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mpairs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mweight\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    749\u001B[0m \u001B[43m                   \u001B[49m\u001B[43mgroup_id\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mgroup_weight\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43msubgroup_id\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mpairs_weight\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mbaseline\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mtimestamp\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mfeature_names\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mfeature_tags\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mthread_count\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    750\u001B[0m \u001B[38;5;28msuper\u001B[39m(Pool, \u001B[38;5;28mself\u001B[39m)\u001B[38;5;241m.\u001B[39m\u001B[38;5;21m__init__\u001B[39m()\n",
      "File \u001B[0;32m~/Documents/1.Projects/class-ranking/intellij-class-usages-analysis/venv/lib/python3.8/site-packages/catboost/core.py:1325\u001B[0m, in \u001B[0;36mPool._init\u001B[0;34m(self, data, label, cat_features, text_features, embedding_features, pairs, weight, group_id, group_weight, subgroup_id, pairs_weight, baseline, timestamp, feature_names, feature_tags, thread_count)\u001B[0m\n\u001B[1;32m   1323\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m feature_tags \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[1;32m   1324\u001B[0m     feature_tags \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_check_transform_tags(feature_tags, feature_names)\n\u001B[0;32m-> 1325\u001B[0m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_init_pool\u001B[49m\u001B[43m(\u001B[49m\u001B[43mdata\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mlabel\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mcat_features\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mtext_features\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43membedding_features\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mpairs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mweight\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1326\u001B[0m \u001B[43m                \u001B[49m\u001B[43mgroup_id\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mgroup_weight\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43msubgroup_id\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mpairs_weight\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mbaseline\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mtimestamp\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mfeature_names\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mfeature_tags\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mthread_count\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m_catboost.pyx:3769\u001B[0m, in \u001B[0;36m_catboost._PoolBase._init_pool\u001B[0;34m()\u001B[0m\n",
      "File \u001B[0;32m_catboost.pyx:3818\u001B[0m, in \u001B[0;36m_catboost._PoolBase._init_pool\u001B[0;34m()\u001B[0m\n",
      "File \u001B[0;32m_catboost.pyx:3652\u001B[0m, in \u001B[0;36m_catboost._PoolBase._init_features_order_layout_pool\u001B[0;34m()\u001B[0m\n",
      "File \u001B[0;32m_catboost.pyx:2651\u001B[0m, in \u001B[0;36m_catboost._set_features_order_data_pd_data_frame\u001B[0;34m()\u001B[0m\n",
      "File \u001B[0;32m_catboost.pyx:2251\u001B[0m, in \u001B[0;36m_catboost.get_cat_factor_bytes_representation\u001B[0;34m()\u001B[0m\n",
      "\u001B[0;31mCatBoostError\u001B[0m: Invalid type for cat_feature[non-default value idx=24,feature_idx=2]=nan : cat_features must be integer or string, real number values and NaN values should be converted to string."
     ]
    }
   ],
   "source": [
    "# Initialize CatBoostRegressor\n",
    "model = CatBoostRegressor(iterations=2,\n",
    "                          learning_rate=1,\n",
    "                          depth=2)\n",
    "# Fit model\n",
    "model.fit(X_train, y_train, cat_features=[0,1,2,3,4,5])\n",
    "# Get predictions\n",
    "preds = model.predict(X_test)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "median_absolute_error(y_test.tolist(), preds)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}