{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "collapsed": true,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import copy\n",
    "import glob\n",
    "import json\n",
    "import os\n",
    "import random\n",
    "import re\n",
    "from collections import Counter\n",
    "from random import shuffle\n",
    "\n",
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import PolynomialFeatures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "outputs": [],
   "source": [
    "random.seed(0)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "load files, build a graph, count indevidual usages \n",
      "10000 files loaded, for current file: direct_usages = 6 | direct_children = 0 \n",
      "20000 files loaded, for current file: direct_usages = 10 | direct_children = 0 \n",
      "30000 files loaded, for current file: direct_usages = 2 | direct_children = 0 \n",
      "40000 files loaded, for current file: direct_usages = 5 | direct_children = 0 \n",
      "50000 files loaded, for current file: direct_usages = 2 | direct_children = 0 \n",
      "53265 files processed \n"
     ]
    }
   ],
   "source": [
    "root_dir = \"/home/kirill/Documents/1.Projects/\" \\\n",
    "           \"class-ranking/intellij-community/\" \\\n",
    "           \"project-processing-results/processing/\" \\\n",
    "           \"java/classes/processing/0.0.1/\"\n",
    "\n",
    "cnt = 0\n",
    "individualUsages = {}  # {className -> {className -> count}}\n",
    "graph = {}  #{className -> [parentNames]}\n",
    "\n",
    "def good(usage) -> bool:\n",
    "    # {'TYPE', 'THIS_EXPRESSION', 'EXTENDS_LIST', 'IMPLEMENTS_LIST', 'METHOD_REF_EXPRESSION', 'EXPRESSION_LIST', 'NEW_EXPRESSION', 'CONDITIONAL_EXPRESSION', 'FIELD', 'ANNOTATION', 'THROWS_LIST', 'SUPER_EXPRESSION', 'JAVA_CODE_REFERENCE', 'REFERENCE_EXPRESSION', 'DOC_REFERENCE_HOLDER'}\n",
    "    if usage[\"features\"][\"referenceType\"] == \"ANNOTATION\":\n",
    "        return False\n",
    "    if usage[\"features\"][\"referenceType\"] == \"DOC_REFERENCE_HOLDER\":\n",
    "        return False\n",
    "    return True\n",
    "\n",
    "def addToUsages(data, individualUsages):\n",
    "    enclosingName = data[\"keyInfo\"][\"name\"]\n",
    "    c = Counter()\n",
    "    for usage in data['usages']:\n",
    "        if good(usage):\n",
    "            c.update([usage['name']])\n",
    "    individualUsages[enclosingName] = c\n",
    "\n",
    "def addToGraph(data, graph):\n",
    "    enclosingName = data[\"keyInfo\"][\"name\"]\n",
    "    extends = data[\"keyInfo\"][\"additionalInfo\"][\"enclosingClassExtendsList\"]\n",
    "    impls = data[\"keyInfo\"][\"additionalInfo\"][\"enclosingClassImplementsList\"]\n",
    "    if enclosingName not in graph:\n",
    "        graph[enclosingName] = set()\n",
    "    for par in (extends + impls):\n",
    "        if par not in graph:\n",
    "            graph[par] = set()\n",
    "        graph[par].update({enclosingName})\n",
    "\n",
    "\n",
    "print(f'load files, build a graph, count indevidual usages ')\n",
    "for filename in glob.glob(root_dir + '**/*.json', recursive=True):\n",
    "    #print(f'name {filename}')\n",
    "    with open(os.path.join(os.getcwd(), filename), 'r') as f:\n",
    "        data = json.load(f)\n",
    "        addToUsages(data, individualUsages)\n",
    "        addToGraph(data, graph)\n",
    "        cnt += 1\n",
    "        if cnt % 10**4 == 0:\n",
    "            print(f'{cnt} files loaded, for current file: direct_usages = {len(individualUsages[data[\"keyInfo\"][\"name\"]])} | direct_children = {len(graph[data[\"keyInfo\"][\"name\"]])} ')\n",
    "print(f'{cnt} files processed ')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000 vertexes evalueted | in com.intellij.openapi.externalSystem.model.execution.ExternalSystemTaskExecutionSettings used 6 classes, 1 children\n",
      "20000 vertexes evalueted | in com.intellij.codeInspection.SimplifyCollectorInspection used 10 classes, 1 children\n",
      "30000 vertexes evalueted | in com.intellij.refactoring.changeSignature.ChangeSignatureParameterUsageInfo used 2 classes, 1 children\n",
      "40000 vertexes evalueted | in com.intellij.structuralsearch.impl.matcher.MatchResultImpl used 5 classes, 1 children\n",
      "50000 vertexes evalueted | in com.intellij.execution.actions.ChooseDebugConfigurationPopupAction used 2 classes, 1 children\n"
     ]
    }
   ],
   "source": [
    "familyUsages = {}  # className -> usages in all children (className -> number)\n",
    "family = {}  # className -> self and all children set(className)\n",
    "parent = {}  # className -> className\n",
    "\n",
    "\n",
    "def dfs(v):\n",
    "    cur_usages = copy.deepcopy(individualUsages[v])\n",
    "    cur_family_set = {v}\n",
    "    for u in graph[v]:\n",
    "        if u not in family:\n",
    "            parent[u] = v\n",
    "            dfs(u)\n",
    "\n",
    "        u_usages, u_child_set = familyUsages[u], family[u]\n",
    "        cur_usages.update(u_usages)\n",
    "        cur_family_set.update(u_child_set)\n",
    "    familyUsages[v], family[v] = cur_usages, cur_family_set\n",
    "\n",
    "\n",
    "v_count = 0\n",
    "for v in individualUsages:\n",
    "    if v not in familyUsages:\n",
    "        dfs(v)\n",
    "    v_count += 1\n",
    "    if v_count % 10 ** 4 == 0:\n",
    "        print(f'{v_count} vertexes evalueted | in {v} used {len(familyUsages[v])} classes, {len(family[v])} children')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "outputs": [],
   "source": [
    "ROOT_CLASS = \"com.intellij.openapi.actionSystem.AnAction\"\n",
    "#print(familyUsages[ROOT_CLASS].most_common())"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "outputs": [],
   "source": [
    "train_test_classes = family[ROOT_CLASS]\n",
    "train_list, test_list = train_test_split(list(train_test_classes), train_size=0.7, random_state=0)\n",
    "test_list, valid_list = train_test_split(test_list, train_size=0.65, random_state=0)\n",
    "trainClasses = set(train_list)\n",
    "testClasses = set(test_list)\n",
    "validClasses = set(valid_list)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "outputs": [],
   "source": [
    "train_usages = set()\n",
    "for c in trainClasses:\n",
    "    train_usages.update(individualUsages[c].keys())"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "outputs": [],
   "source": [
    "firstCharToNameList = {}\n",
    "for k, v in familyUsages[ROOT_CLASS].most_common():\n",
    "    if k not in train_usages:\n",
    "        continue\n",
    "    first_char = k.rpartition('.')[2][0]\n",
    "    if first_char not in firstCharToNameList:\n",
    "        firstCharToNameList[first_char] = []\n",
    "    firstCharToNameList[first_char].append(k)\n",
    "\n",
    "with open('FirstCharToNameList.txt', 'w') as convert_file:\n",
    "    convert_file.write(json.dumps(firstCharToNameList))\n",
    "\n",
    "# for k in firstCharToNameList:\n",
    "#     print(f'{k} {len(firstCharToNameList[k])}')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "outputs": [],
   "source": [
    "firstCharToNameListSampling = {}\n",
    "for k, v in familyUsages[ROOT_CLASS].most_common():\n",
    "    if k not in train_usages:\n",
    "        continue\n",
    "    first_char = k.rpartition('.')[2][0]\n",
    "    if first_char not in firstCharToNameListSampling:\n",
    "        firstCharToNameListSampling[first_char] = []\n",
    "    firstCharToNameListSampling[first_char] += [k] * v\n",
    "\n",
    "for k in firstCharToNameListSampling:\n",
    "    shuffle(firstCharToNameListSampling[k])\n",
    "\n",
    "with open('FirstCharToNameListSampling.txt', 'w') as convert_file:\n",
    "    convert_file.write(json.dumps(firstCharToNameListSampling))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "outputs": [],
   "source": [
    "def listToStr(df, col):\n",
    "    tmp = df[col].isnull(), col\n",
    "    df.loc[tmp] = df.loc[tmp].apply(lambda x: [])\n",
    "    df[col] = df[col].apply(lambda x: \" \".join(x))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "outputs": [],
   "source": [
    "def splitCamelCase(name: str):\n",
    "    res = []\n",
    "    for rname in name.split(' '):\n",
    "        rname = rname.strip('.')\n",
    "        if '.' in rname:\n",
    "            rname = rname.rpartition('.')[2]\n",
    "        res += re.sub('([A-Z][a-z]+)', r' \\1', re.sub('([A-Z]+)', r' \\1', rname)).split()\n",
    "        #res += [rname]\n",
    "    return res"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "outputs": [],
   "source": [
    "fnameToSize = {\n",
    "    'name': 5,\n",
    "    'features.enclosingScopeName': 5,\n",
    "    'features.enclosingClassName': 5,\n",
    "    'features.variablesTypesInScope': 15\n",
    "}\n",
    "\n",
    "\n",
    "def namesToCats(usage):\n",
    "    usage = copy.deepcopy(usage)\n",
    "    for k in list(usage.keys()):\n",
    "        if k not in fnameToSize:\n",
    "            continue\n",
    "        v = usage[k]\n",
    "        if isinstance(v, list):\n",
    "            v = \" \".join(v)\n",
    "        vl = splitCamelCase(v)\n",
    "        #vl.sort()\n",
    "        vl.reverse()\n",
    "        if len(vl) < fnameToSize[k]:\n",
    "            vl += [''] * (fnameToSize[k] - len(vl))\n",
    "        if len(vl) > fnameToSize[k]:\n",
    "            vl = vl[:fnameToSize[k]]\n",
    "        for i, w in enumerate(vl):\n",
    "            usage[f'{k}_{i}'] = w\n",
    "        del usage[k]\n",
    "    return usage\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'filePath': 'platform/xdebugger-impl/src/com/intellij/xdebugger/impl/ui/tree/actions/XJumpToTypeSourceAction.java', 'textOffset': 958, 'features.referenceType': 'EXTENDS_LIST', 'features.lineInFile': 23, 'correct': 1, 'firstChar': 'X', 'group': 0, 'name_0': 'Base', 'name_1': 'Action', 'name_2': 'Source', 'name_3': 'To', 'name_4': 'Jump', 'features.enclosingClassName_0': 'Action', 'features.enclosingClassName_1': 'Source', 'features.enclosingClassName_2': 'Type', 'features.enclosingClassName_3': 'To', 'features.enclosingClassName_4': 'Jump'}\n",
      "2810 files loaded, 611400 usages\n",
      "test shape (224562, 38)\n",
      "train shape (267732, 38)\n",
      "valid shape (119106, 38)\n"
     ]
    },
    {
     "data": {
      "text/plain": "features.referenceType               object\ncorrect                               int64\nfirstChar                            object\ngroup                                 int64\nname_0                               object\nname_1                               object\nname_2                               object\nname_3                               object\nname_4                               object\nfeatures.enclosingClassName_0        object\nfeatures.enclosingClassName_1        object\nfeatures.enclosingClassName_2        object\nfeatures.enclosingClassName_3        object\nfeatures.enclosingClassName_4        object\nfeatures.scopeKind                   object\nfeatures.enclosingScopeName_0        object\nfeatures.enclosingScopeName_1        object\nfeatures.enclosingScopeName_2        object\nfeatures.enclosingScopeName_3        object\nfeatures.enclosingScopeName_4        object\nfeatures.variablesTypesInScope_0     object\nfeatures.variablesTypesInScope_1     object\nfeatures.variablesTypesInScope_2     object\nfeatures.variablesTypesInScope_3     object\nfeatures.variablesTypesInScope_4     object\nfeatures.variablesTypesInScope_5     object\nfeatures.variablesTypesInScope_6     object\nfeatures.variablesTypesInScope_7     object\nfeatures.variablesTypesInScope_8     object\nfeatures.variablesTypesInScope_9     object\nfeatures.variablesTypesInScope_10    object\nfeatures.variablesTypesInScope_11    object\nfeatures.variablesTypesInScope_12    object\nfeatures.variablesTypesInScope_13    object\nfeatures.variablesTypesInScope_14    object\nfeatures.insideStatement_0           object\nfeatures.insideStatement_1           object\nfeatures.insideStatement_2           object\ndtype: object"
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "\n",
    "cnt = 0\n",
    "cntu = 0\n",
    "list_of_dfs_train = []\n",
    "list_of_dfs_test = []\n",
    "list_of_dfs_valid = []\n",
    "group_id = 0\n",
    "for filename in glob.glob(root_dir + '**/*.json', recursive=True):\n",
    "    enclosingClassName = filename.rpartition('/')[0].rpartition('/')[2]\n",
    "    if enclosingClassName not in train_test_classes:\n",
    "        continue\n",
    "    with open(os.path.join(os.getcwd(), filename), 'r') as f:\n",
    "        data = json.load(f)\n",
    "        data_usages = []\n",
    "        for usage in data[\"usages\"]:\n",
    "            if not good(usage):\n",
    "                continue\n",
    "            usage = pd.json_normalize(usage).to_dict(orient='records')[0]\n",
    "            usage['features.enclosingClassName'] = enclosingClassName\n",
    "            usage['correct'] = 1\n",
    "            usage['firstChar'] = usage['name'].rpartition('.')[2][0]\n",
    "            usage['group'] = group_id\n",
    "            group_id += 1\n",
    "            if group_id == 1:\n",
    "                print(namesToCats(usage))\n",
    "            data_usages.append(namesToCats(usage))\n",
    "\n",
    "            if enclosingClassName in trainClasses:\n",
    "                negatives = 8\n",
    "            else:\n",
    "                negatives = 25\n",
    "\n",
    "            for i in range(negatives):\n",
    "                usage_negative = copy.deepcopy(usage)\n",
    "                while True:\n",
    "                    new_name = random.choice(firstCharToNameListSampling[usage['firstChar']])  #?\n",
    "                    if usage['name'] != new_name:\n",
    "                        usage_negative['name'] = new_name\n",
    "                        usage_negative['correct'] = 0\n",
    "                        break\n",
    "                data_usages.append(namesToCats(usage_negative))\n",
    "\n",
    "        df = pd.json_normalize(data_usages)\n",
    "\n",
    "\n",
    "        df = df.drop(columns=['filePath', 'textOffset', 'features.lineInFile'])\n",
    "        if enclosingClassName in trainClasses:\n",
    "            list_of_dfs_train.append(df)\n",
    "        if enclosingClassName in testClasses:\n",
    "            list_of_dfs_test.append(df)\n",
    "        if enclosingClassName in validClasses:\n",
    "            list_of_dfs_valid.append(df)\n",
    "        cntu += len(data_usages)\n",
    "        cnt += 1\n",
    "\n",
    "df_train_cat = pd.concat(list_of_dfs_train, axis=0, ignore_index=True)\n",
    "df_test_cat = pd.concat(list_of_dfs_test, axis=0, ignore_index=True)\n",
    "df_valid_cat = pd.concat(list_of_dfs_valid, axis=0, ignore_index=True)\n",
    "\n",
    "# listToStr(df_train_raw, 'features.variablesTypesInScope')\n",
    "# listToStr(df_test_raw, 'features.variablesTypesInScope')\n",
    "# listToStr(df_valid_raw, 'features.variablesTypesInScope')\n",
    "df_train_cat.fillna('', inplace=True)\n",
    "df_test_cat.fillna('', inplace=True)\n",
    "df_valid_cat.fillna('', inplace=True)\n",
    "\n",
    "print(f'{cnt} files loaded, {cntu} usages')\n",
    "\n",
    "print(f'test shape {df_test_cat.shape}')\n",
    "print(f'train shape {df_train_cat.shape}')\n",
    "print(f'valid shape {df_valid_cat.shape}')\n",
    "df_train_cat.dtypes\n",
    "\n",
    "# will we know referenceType irl ?"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train0 ########## ------> :\n",
      "    features.referenceType  correct firstChar  group  name_0 name_1 name_2  \\\n",
      "10                   TYPE        0         X      1  Bundle    Dom    Xml   \n",
      "\n",
      "   name_3 name_4 features.enclosingClassName_0  ...  \\\n",
      "10                                      Action  ...   \n",
      "\n",
      "   features.variablesTypesInScope_8 features.variablesTypesInScope_9  \\\n",
      "10                                                                     \n",
      "\n",
      "   features.variablesTypesInScope_10 features.variablesTypesInScope_11  \\\n",
      "10                                                                       \n",
      "\n",
      "   features.variablesTypesInScope_12 features.variablesTypesInScope_13  \\\n",
      "10                                                                       \n",
      "\n",
      "   features.variablesTypesInScope_14 features.insideStatement_0  \\\n",
      "10                                                                \n",
      "\n",
      "   features.insideStatement_1 features.insideStatement_2  \n",
      "10                                                        \n",
      "\n",
      "[1 rows x 38 columns]\n",
      "test0  ########## ------> :\n",
      "    features.referenceType  correct firstChar  group   name_0   name_1  name_2  \\\n",
      "10           EXTENDS_LIST        0         A     24  Watcher  Windows  Active   \n",
      "\n",
      "   name_3 name_4 features.enclosingClassName_0  ...  \\\n",
      "10                                      Action  ...   \n",
      "\n",
      "   features.variablesTypesInScope_8 features.variablesTypesInScope_9  \\\n",
      "10                                                                     \n",
      "\n",
      "   features.variablesTypesInScope_10 features.variablesTypesInScope_11  \\\n",
      "10                                                                       \n",
      "\n",
      "   features.variablesTypesInScope_12 features.variablesTypesInScope_13  \\\n",
      "10                                                                       \n",
      "\n",
      "   features.variablesTypesInScope_14 features.insideStatement_0  \\\n",
      "10                                                                \n",
      "\n",
      "   features.insideStatement_1 features.insideStatement_2  \n",
      "10                                                        \n",
      "\n",
      "[1 rows x 38 columns]\n",
      "valid0  ########## ------> :\n",
      "    features.referenceType  correct firstChar  group    name_0 name_1 name_2  \\\n",
      "10           EXTENDS_LIST        0         T     39  Settings   Task          \n",
      "\n",
      "   name_3 name_4 features.enclosingClassName_0  ...  \\\n",
      "10                                      Action  ...   \n",
      "\n",
      "   features.variablesTypesInScope_8 features.variablesTypesInScope_9  \\\n",
      "10                                                                     \n",
      "\n",
      "   features.variablesTypesInScope_10 features.variablesTypesInScope_11  \\\n",
      "10                                                                       \n",
      "\n",
      "   features.variablesTypesInScope_12 features.variablesTypesInScope_13  \\\n",
      "10                                                                       \n",
      "\n",
      "   features.variablesTypesInScope_14 features.insideStatement_0  \\\n",
      "10                                                                \n",
      "\n",
      "   features.insideStatement_1 features.insideStatement_2  \n",
      "10                                                        \n",
      "\n",
      "[1 rows x 38 columns]\n"
     ]
    }
   ],
   "source": [
    "print(f'train0 ########## ------> :\\n {df_train_cat.loc[[10]]}')\n",
    "print(f'test0  ########## ------> :\\n {df_test_cat.loc[[10]]}')\n",
    "print(f'valid0  ########## ------> :\\n {df_valid_cat.loc[[10]]}')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "outputs": [],
   "source": [
    "df_train_cat.to_csv('train_cat.csv')\n",
    "\n",
    "df_test_cat.to_csv('test_cat.csv')\n",
    "\n",
    "df_valid_cat.to_csv('valid_cat.csv')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "outputs": [
    {
     "data": {
      "text/plain": "['features.referenceType',\n 'correct',\n 'firstChar',\n 'group',\n 'name_0',\n 'name_1',\n 'name_2',\n 'name_3',\n 'name_4',\n 'features.enclosingClassName_0',\n 'features.enclosingClassName_1',\n 'features.enclosingClassName_2',\n 'features.enclosingClassName_3',\n 'features.enclosingClassName_4',\n 'features.scopeKind',\n 'features.enclosingScopeName_0',\n 'features.enclosingScopeName_1',\n 'features.enclosingScopeName_2',\n 'features.enclosingScopeName_3',\n 'features.enclosingScopeName_4',\n 'features.variablesTypesInScope_0',\n 'features.variablesTypesInScope_1',\n 'features.variablesTypesInScope_2',\n 'features.variablesTypesInScope_3',\n 'features.variablesTypesInScope_4',\n 'features.variablesTypesInScope_5',\n 'features.variablesTypesInScope_6',\n 'features.variablesTypesInScope_7',\n 'features.variablesTypesInScope_8',\n 'features.variablesTypesInScope_9',\n 'features.variablesTypesInScope_10',\n 'features.variablesTypesInScope_11',\n 'features.variablesTypesInScope_12',\n 'features.variablesTypesInScope_13',\n 'features.variablesTypesInScope_14',\n 'features.insideStatement_0',\n 'features.insideStatement_1',\n 'features.insideStatement_2']"
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train_cat.columns.tolist()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}